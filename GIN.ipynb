{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import sys\n",
    "import os\n",
    "from utils import *\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0:3], device_type='GPU')"
   ]
  },
  {
   "source": [
    "This layer computes for each node \\(i\\):\n",
    "\n",
    "$$\\Z_i = \\textrm{MLP}\\big( (1 + \\epsilon) \\cdot \\X_i + \\sum\\limits_{j \\in \\mathcal{N}(i)} \\X_j \\big)$$\n",
    "\n",
    "where MLP is a multi-layer perceptron."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csr_to_SparseTensor(csr_matrix):\n",
    "    if sp.isspmatrix_csr(csr_matrix):\n",
    "            csr_matrix = csr_matrix.tocoo()\n",
    "    row = csr_matrix.row\n",
    "    col = csr_matrix.col\n",
    "    pos = np.c_[row,col]\n",
    "    data = csr_matrix.data\n",
    "    shape = csr_matrix.shape\n",
    "    return tf.SparseTensor(pos, data, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cora\"\n",
    "\n",
    "adj, whole_features, whole_labels, train_idx, val_idx, test_idx = load_data(dataset_name)\n",
    "adj_SparseTensor = convert_csr_to_SparseTensor(adj)\n",
    "features = preprocess_features(whole_features).todense()\n",
    "\n",
    "num_nodes = features.shape[0]\n",
    "feature_dim = features.shape[1]\n",
    "epochs = 500\n",
    "n_classes = whole_labels.shape[1]\n",
    "dropout_rate = 0.6 \n",
    "learning_rate = 5e-3\n",
    "L2_reg = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINLayer(keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 output_dim, \n",
    "                 mlp_num, \n",
    "                 hidden_units,\n",
    "                 adj, \n",
    "                 num_nodes,\n",
    "                 epsilon=0,\n",
    "                 epsilon_learnable = True,\n",
    "                 mlp_activation = keras.activations.relu,\n",
    "                 activation = None,\n",
    "                 use_bias = False):\n",
    "        super(GINLayer,self).__init__(self)\n",
    "        self.output_dim = output_dim,\n",
    "        self.adj = adj\n",
    "        self.epsilon = epsilon\n",
    "        self.mlp_num = mlp_num\n",
    "        self.mlp_activation = mlp_activation\n",
    "        self.activation = activation\n",
    "        self.use_bias = use_bias\n",
    "        self.hidden_units = hidden_units  # 每个MLP的units数\n",
    "        self.epsilon_learnable = epsilon_learnable\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.hidden_units is not None and self.mlp_num > 0:\n",
    "            self.mlp = keras.models.Sequential([\n",
    "                keras.layers.Dense(units=units, activation=self.mlp_activation, use_bias=self.use_bias)\n",
    "                for units in self.hidden_units\n",
    "            ])\n",
    "        self.output_dense = keras.layers.Dense(units=self.output_dim[0], use_bias=self.use_bias, activation= self.activation)\n",
    "        if self.epsilon_learnable:\n",
    "            self.eps = self.add_weight(name = \"epsilon\",\n",
    "                            shape = (1,),\n",
    "                            initializer=keras.initializers.zeros,\n",
    "                            trainable=True)\n",
    "        else:\n",
    "            self.eps = tf.constant(self.epsilon)\n",
    "        self.built = True\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def _message_passing(self, adj, features):\n",
    "        index_i = adj.indices[:,0]\n",
    "        index_j = adj.indices[:,1]\n",
    "        messages = tf.gather(features, index_j)\n",
    "        agg = tf.math.unsorted_segment_sum(messages, index_i, self.num_nodes)\n",
    "        # agg = scatter_sum(messages, index_i, self.num_nodes)\n",
    "        return agg\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = inputs\n",
    "        assert keras.backend.is_sparse(self.adj), \"Adjcency Matrix Must be Sparse Tensor\"\n",
    "        assert keras.backend.ndim(features), \"Features Must be Rank 2\"\n",
    "        agg = self._message_passing(self.adj, features)\n",
    "        if self.hidden_units is not None and self.mlp_num > 0:\n",
    "            mlp_output = self.mlp((1.+ self.eps) * features + agg)\n",
    "            out = self.output_dense(mlp_output)\n",
    "        else:\n",
    "            out = self.output_dense((1.+ self.eps) * features + agg)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 1433)]            0         \n_________________________________________________________________\ngin_layer_6 (GINLayer)       (2708, 16)                23185     \n_________________________________________________________________\ngin_layer_7 (GINLayer)       (2708, 7)                 113       \n=================================================================\nTotal params: 23,298\nTrainable params: 23,298\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape = (feature_dim,))\n",
    "# 第一层的MLP有两层\n",
    "gin1 = GINLayer(output_dim=16, \n",
    "                num_nodes = num_nodes,\n",
    "                mlp_num=1, \n",
    "                hidden_units=[16], \n",
    "                adj = adj_SparseTensor, \n",
    "                epsilon_learnable=True, \n",
    "                activation=keras.activations.relu)(model_input)\n",
    "gin2 = GINLayer(output_dim=n_classes,\n",
    "                num_nodes = num_nodes,\n",
    "                mlp_num=0, \n",
    "                hidden_units=None, \n",
    "                adj=adj_SparseTensor,\n",
    "                epsilon_learnable=True, \n",
    "                activation=keras.activations.softmax)(gin1)\n",
    "# gin1 = GINLayer(output_dim=128, \n",
    "#                 mlp_num=0, \n",
    "#                 hidden_units=None, \n",
    "#                 adj = adj_SparseTensor, \n",
    "#                 epsilon_learnable=True, \n",
    "#                 activation=keras.activations.relu)(model_input)\n",
    "\n",
    "model = keras.models.Model(inputs = model_input, outputs = gin2)\n",
    "model.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              weighted_metrics=['categorical_crossentropy', 'acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc: 1.0000 - val_loss: 0.3377 - val_categorical_crossentropy: 1.8288 - val_acc: 0.7420\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.8518e-05 - categorical_crossentropy: 7.4504e-04 - acc: 1.0000 - val_loss: 0.3379 - val_categorical_crossentropy: 1.8300 - val_acc: 0.7420\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.8148e-05 - categorical_crossentropy: 7.3789e-04 - acc: 1.0000 - val_loss: 0.3381 - val_categorical_crossentropy: 1.8312 - val_acc: 0.7420\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.7782e-05 - categorical_crossentropy: 7.3082e-04 - acc: 1.0000 - val_loss: 0.3383 - val_categorical_crossentropy: 1.8324 - val_acc: 0.7420\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.7422e-05 - categorical_crossentropy: 7.2385e-04 - acc: 1.0000 - val_loss: 0.3385 - val_categorical_crossentropy: 1.8335 - val_acc: 0.7420\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.7067e-05 - categorical_crossentropy: 7.1698e-04 - acc: 1.0000 - val_loss: 0.3388 - val_categorical_crossentropy: 1.8348 - val_acc: 0.7420\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.6718e-05 - categorical_crossentropy: 7.1022e-04 - acc: 1.0000 - val_loss: 0.3390 - val_categorical_crossentropy: 1.8360 - val_acc: 0.7440\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.6373e-05 - categorical_crossentropy: 7.0356e-04 - acc: 1.0000 - val_loss: 0.3392 - val_categorical_crossentropy: 1.8371 - val_acc: 0.7440\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.6033e-05 - categorical_crossentropy: 6.9699e-04 - acc: 1.0000 - val_loss: 0.3394 - val_categorical_crossentropy: 1.8383 - val_acc: 0.7440\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.5698e-05 - categorical_crossentropy: 6.9050e-04 - acc: 1.0000 - val_loss: 0.3396 - val_categorical_crossentropy: 1.8395 - val_acc: 0.7440\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5368e-05 - categorical_crossentropy: 6.8411e-04 - acc: 1.0000 - val_loss: 0.3399 - val_categorical_crossentropy: 1.8407 - val_acc: 0.7440\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5042e-05 - categorical_crossentropy: 6.7781e-04 - acc: 1.0000 - val_loss: 0.3401 - val_categorical_crossentropy: 1.8419 - val_acc: 0.7440\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.4720e-05 - categorical_crossentropy: 6.7159e-04 - acc: 1.0000 - val_loss: 0.3403 - val_categorical_crossentropy: 1.8431 - val_acc: 0.7440\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.4404e-05 - categorical_crossentropy: 6.6547e-04 - acc: 1.0000 - val_loss: 0.3405 - val_categorical_crossentropy: 1.8443 - val_acc: 0.7440\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.4091e-05 - categorical_crossentropy: 6.5942e-04 - acc: 1.0000 - val_loss: 0.3407 - val_categorical_crossentropy: 1.8454 - val_acc: 0.7440\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.3783e-05 - categorical_crossentropy: 6.5346e-04 - acc: 1.0000 - val_loss: 0.3410 - val_categorical_crossentropy: 1.8466 - val_acc: 0.7440\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.3480e-05 - categorical_crossentropy: 6.4760e-04 - acc: 1.0000 - val_loss: 0.3412 - val_categorical_crossentropy: 1.8477 - val_acc: 0.7440\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.3181e-05 - categorical_crossentropy: 6.4181e-04 - acc: 1.0000 - val_loss: 0.3414 - val_categorical_crossentropy: 1.8489 - val_acc: 0.7440\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.2885e-05 - categorical_crossentropy: 6.3608e-04 - acc: 1.0000 - val_loss: 0.3416 - val_categorical_crossentropy: 1.8500 - val_acc: 0.7440\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.2593e-05 - categorical_crossentropy: 6.3044e-04 - acc: 1.0000 - val_loss: 0.3418 - val_categorical_crossentropy: 1.8512 - val_acc: 0.7440\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.2305e-05 - categorical_crossentropy: 6.2488e-04 - acc: 1.0000 - val_loss: 0.3420 - val_categorical_crossentropy: 1.8523 - val_acc: 0.7440\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.2022e-05 - categorical_crossentropy: 6.1939e-04 - acc: 1.0000 - val_loss: 0.3422 - val_categorical_crossentropy: 1.8535 - val_acc: 0.7440\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.1742e-05 - categorical_crossentropy: 6.1399e-04 - acc: 1.0000 - val_loss: 0.3424 - val_categorical_crossentropy: 1.8546 - val_acc: 0.7440\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1466e-05 - categorical_crossentropy: 6.0864e-04 - acc: 1.0000 - val_loss: 0.3426 - val_categorical_crossentropy: 1.8557 - val_acc: 0.7440\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.1194e-05 - categorical_crossentropy: 6.0338e-04 - acc: 1.0000 - val_loss: 0.3428 - val_categorical_crossentropy: 1.8569 - val_acc: 0.7440\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.0925e-05 - categorical_crossentropy: 5.9817e-04 - acc: 1.0000 - val_loss: 0.3430 - val_categorical_crossentropy: 1.8579 - val_acc: 0.7440\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0660e-05 - categorical_crossentropy: 5.9304e-04 - acc: 1.0000 - val_loss: 0.3433 - val_categorical_crossentropy: 1.8591 - val_acc: 0.7440\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0398e-05 - categorical_crossentropy: 5.8799e-04 - acc: 1.0000 - val_loss: 0.3435 - val_categorical_crossentropy: 1.8602 - val_acc: 0.7440\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0140e-05 - categorical_crossentropy: 5.8300e-04 - acc: 1.0000 - val_loss: 0.3437 - val_categorical_crossentropy: 1.8613 - val_acc: 0.7440\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.9885e-05 - categorical_crossentropy: 5.7806e-04 - acc: 1.0000 - val_loss: 0.3439 - val_categorical_crossentropy: 1.8624 - val_acc: 0.7440\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9633e-05 - categorical_crossentropy: 5.7319e-04 - acc: 1.0000 - val_loss: 0.3441 - val_categorical_crossentropy: 1.8635 - val_acc: 0.7440\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.9385e-05 - categorical_crossentropy: 5.6840e-04 - acc: 1.0000 - val_loss: 0.3443 - val_categorical_crossentropy: 1.8647 - val_acc: 0.7440\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.9140e-05 - categorical_crossentropy: 5.6365e-04 - acc: 1.0000 - val_loss: 0.3445 - val_categorical_crossentropy: 1.8658 - val_acc: 0.7440\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8898e-05 - categorical_crossentropy: 5.5896e-04 - acc: 1.0000 - val_loss: 0.3447 - val_categorical_crossentropy: 1.8669 - val_acc: 0.7440\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8659e-05 - categorical_crossentropy: 5.5434e-04 - acc: 1.0000 - val_loss: 0.3449 - val_categorical_crossentropy: 1.8680 - val_acc: 0.7440\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.8422e-05 - categorical_crossentropy: 5.4977e-04 - acc: 1.0000 - val_loss: 0.3451 - val_categorical_crossentropy: 1.8691 - val_acc: 0.7440\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.8189e-05 - categorical_crossentropy: 5.4526e-04 - acc: 1.0000 - val_loss: 0.3453 - val_categorical_crossentropy: 1.8702 - val_acc: 0.7440\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.7959e-05 - categorical_crossentropy: 5.4082e-04 - acc: 1.0000 - val_loss: 0.3455 - val_categorical_crossentropy: 1.8713 - val_acc: 0.7440\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7732e-05 - categorical_crossentropy: 5.3642e-04 - acc: 1.0000 - val_loss: 0.3457 - val_categorical_crossentropy: 1.8723 - val_acc: 0.7440\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.7508e-05 - categorical_crossentropy: 5.3208e-04 - acc: 1.0000 - val_loss: 0.3459 - val_categorical_crossentropy: 1.8735 - val_acc: 0.7440\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7286e-05 - categorical_crossentropy: 5.2779e-04 - acc: 1.0000 - val_loss: 0.3461 - val_categorical_crossentropy: 1.8746 - val_acc: 0.7440\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.7067e-05 - categorical_crossentropy: 5.2356e-04 - acc: 1.0000 - val_loss: 0.3463 - val_categorical_crossentropy: 1.8756 - val_acc: 0.7440\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.6851e-05 - categorical_crossentropy: 5.1937e-04 - acc: 1.0000 - val_loss: 0.3465 - val_categorical_crossentropy: 1.8767 - val_acc: 0.7460\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.6637e-05 - categorical_crossentropy: 5.1523e-04 - acc: 1.0000 - val_loss: 0.3467 - val_categorical_crossentropy: 1.8778 - val_acc: 0.7460\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.6425e-05 - categorical_crossentropy: 5.1114e-04 - acc: 1.0000 - val_loss: 0.3469 - val_categorical_crossentropy: 1.8789 - val_acc: 0.7460\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6217e-05 - categorical_crossentropy: 5.0711e-04 - acc: 1.0000 - val_loss: 0.3471 - val_categorical_crossentropy: 1.8800 - val_acc: 0.7460\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.6011e-05 - categorical_crossentropy: 5.0313e-04 - acc: 1.0000 - val_loss: 0.3473 - val_categorical_crossentropy: 1.8810 - val_acc: 0.7460\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.5808e-05 - categorical_crossentropy: 4.9920e-04 - acc: 1.0000 - val_loss: 0.3475 - val_categorical_crossentropy: 1.8821 - val_acc: 0.7460\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5607e-05 - categorical_crossentropy: 4.9531e-04 - acc: 1.0000 - val_loss: 0.3477 - val_categorical_crossentropy: 1.8831 - val_acc: 0.7460\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.5408e-05 - categorical_crossentropy: 4.9146e-04 - acc: 1.0000 - val_loss: 0.3479 - val_categorical_crossentropy: 1.8841 - val_acc: 0.7460\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.5212e-05 - categorical_crossentropy: 4.8766e-04 - acc: 1.0000 - val_loss: 0.3481 - val_categorical_crossentropy: 1.8852 - val_acc: 0.7460\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5019e-05 - categorical_crossentropy: 4.8393e-04 - acc: 1.0000 - val_loss: 0.3483 - val_categorical_crossentropy: 1.8862 - val_acc: 0.7460\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4826e-05 - categorical_crossentropy: 4.8021e-04 - acc: 1.0000 - val_loss: 0.3485 - val_categorical_crossentropy: 1.8872 - val_acc: 0.7460\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4637e-05 - categorical_crossentropy: 4.7655e-04 - acc: 1.0000 - val_loss: 0.3486 - val_categorical_crossentropy: 1.8883 - val_acc: 0.7460\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4450e-05 - categorical_crossentropy: 4.7294e-04 - acc: 1.0000 - val_loss: 0.3488 - val_categorical_crossentropy: 1.8893 - val_acc: 0.7440\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4265e-05 - categorical_crossentropy: 4.6935e-04 - acc: 1.0000 - val_loss: 0.3490 - val_categorical_crossentropy: 1.8904 - val_acc: 0.7440\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.4082e-05 - categorical_crossentropy: 4.6581e-04 - acc: 1.0000 - val_loss: 0.3492 - val_categorical_crossentropy: 1.8914 - val_acc: 0.7440\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3901e-05 - categorical_crossentropy: 4.6232e-04 - acc: 1.0000 - val_loss: 0.3494 - val_categorical_crossentropy: 1.8925 - val_acc: 0.7440\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.3722e-05 - categorical_crossentropy: 4.5886e-04 - acc: 1.0000 - val_loss: 0.3496 - val_categorical_crossentropy: 1.8934 - val_acc: 0.7440\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3545e-05 - categorical_crossentropy: 4.5543e-04 - acc: 1.0000 - val_loss: 0.3498 - val_categorical_crossentropy: 1.8944 - val_acc: 0.7440\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.3371e-05 - categorical_crossentropy: 4.5206e-04 - acc: 1.0000 - val_loss: 0.3500 - val_categorical_crossentropy: 1.8954 - val_acc: 0.7440\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3198e-05 - categorical_crossentropy: 4.4872e-04 - acc: 1.0000 - val_loss: 0.3501 - val_categorical_crossentropy: 1.8964 - val_acc: 0.7440\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.3027e-05 - categorical_crossentropy: 4.4541e-04 - acc: 1.0000 - val_loss: 0.3503 - val_categorical_crossentropy: 1.8974 - val_acc: 0.7440\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2858e-05 - categorical_crossentropy: 4.4215e-04 - acc: 1.0000 - val_loss: 0.3505 - val_categorical_crossentropy: 1.8984 - val_acc: 0.7440\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.2691e-05 - categorical_crossentropy: 4.3891e-04 - acc: 1.0000 - val_loss: 0.3507 - val_categorical_crossentropy: 1.8994 - val_acc: 0.7440\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2526e-05 - categorical_crossentropy: 4.3571e-04 - acc: 1.0000 - val_loss: 0.3509 - val_categorical_crossentropy: 1.9004 - val_acc: 0.7440\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.2362e-05 - categorical_crossentropy: 4.3255e-04 - acc: 1.0000 - val_loss: 0.3511 - val_categorical_crossentropy: 1.9014 - val_acc: 0.7440\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.2201e-05 - categorical_crossentropy: 4.2943e-04 - acc: 1.0000 - val_loss: 0.3513 - val_categorical_crossentropy: 1.9024 - val_acc: 0.7440\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.2041e-05 - categorical_crossentropy: 4.2634e-04 - acc: 1.0000 - val_loss: 0.3514 - val_categorical_crossentropy: 1.9034 - val_acc: 0.7440\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.1883e-05 - categorical_crossentropy: 4.2328e-04 - acc: 1.0000 - val_loss: 0.3516 - val_categorical_crossentropy: 1.9044 - val_acc: 0.7460\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1726e-05 - categorical_crossentropy: 4.2025e-04 - acc: 1.0000 - val_loss: 0.3518 - val_categorical_crossentropy: 1.9054 - val_acc: 0.7460\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1572e-05 - categorical_crossentropy: 4.1726e-04 - acc: 1.0000 - val_loss: 0.3520 - val_categorical_crossentropy: 1.9064 - val_acc: 0.7440\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1419e-05 - categorical_crossentropy: 4.1431e-04 - acc: 1.0000 - val_loss: 0.3522 - val_categorical_crossentropy: 1.9073 - val_acc: 0.7440\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1268e-05 - categorical_crossentropy: 4.1138e-04 - acc: 1.0000 - val_loss: 0.3523 - val_categorical_crossentropy: 1.9083 - val_acc: 0.7440\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1118e-05 - categorical_crossentropy: 4.0849e-04 - acc: 1.0000 - val_loss: 0.3525 - val_categorical_crossentropy: 1.9093 - val_acc: 0.7440\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0970e-05 - categorical_crossentropy: 4.0563e-04 - acc: 1.0000 - val_loss: 0.3527 - val_categorical_crossentropy: 1.9102 - val_acc: 0.7440\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 2.0824e-05 - categorical_crossentropy: 4.0279e-04 - acc: 1.0000 - val_loss: 0.3529 - val_categorical_crossentropy: 1.9112 - val_acc: 0.7440\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0679e-05 - categorical_crossentropy: 3.9999e-04 - acc: 1.0000 - val_loss: 0.3530 - val_categorical_crossentropy: 1.9121 - val_acc: 0.7440\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.0536e-05 - categorical_crossentropy: 3.9722e-04 - acc: 1.0000 - val_loss: 0.3532 - val_categorical_crossentropy: 1.9130 - val_acc: 0.7440\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0394e-05 - categorical_crossentropy: 3.9449e-04 - acc: 1.0000 - val_loss: 0.3534 - val_categorical_crossentropy: 1.9139 - val_acc: 0.7440\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0254e-05 - categorical_crossentropy: 3.9177e-04 - acc: 1.0000 - val_loss: 0.3536 - val_categorical_crossentropy: 1.9149 - val_acc: 0.7440\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0114e-05 - categorical_crossentropy: 3.8907e-04 - acc: 1.0000 - val_loss: 0.3537 - val_categorical_crossentropy: 1.9159 - val_acc: 0.7440\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9978e-05 - categorical_crossentropy: 3.8643e-04 - acc: 1.0000 - val_loss: 0.3539 - val_categorical_crossentropy: 1.9168 - val_acc: 0.7440\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9842e-05 - categorical_crossentropy: 3.8380e-04 - acc: 1.0000 - val_loss: 0.3541 - val_categorical_crossentropy: 1.9177 - val_acc: 0.7440\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.9707e-05 - categorical_crossentropy: 3.8119e-04 - acc: 1.0000 - val_loss: 0.3542 - val_categorical_crossentropy: 1.9185 - val_acc: 0.7440\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9574e-05 - categorical_crossentropy: 3.7862e-04 - acc: 1.0000 - val_loss: 0.3544 - val_categorical_crossentropy: 1.9195 - val_acc: 0.7440\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9442e-05 - categorical_crossentropy: 3.7607e-04 - acc: 1.0000 - val_loss: 0.3546 - val_categorical_crossentropy: 1.9204 - val_acc: 0.7440\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.9312e-05 - categorical_crossentropy: 3.7355e-04 - acc: 1.0000 - val_loss: 0.3548 - val_categorical_crossentropy: 1.9213 - val_acc: 0.7440\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9182e-05 - categorical_crossentropy: 3.7104e-04 - acc: 1.0000 - val_loss: 0.3549 - val_categorical_crossentropy: 1.9222 - val_acc: 0.7440\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9054e-05 - categorical_crossentropy: 3.6856e-04 - acc: 1.0000 - val_loss: 0.3551 - val_categorical_crossentropy: 1.9231 - val_acc: 0.7440\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.8928e-05 - categorical_crossentropy: 3.6612e-04 - acc: 1.0000 - val_loss: 0.3552 - val_categorical_crossentropy: 1.9240 - val_acc: 0.7440\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8803e-05 - categorical_crossentropy: 3.6370e-04 - acc: 1.0000 - val_loss: 0.3554 - val_categorical_crossentropy: 1.9249 - val_acc: 0.7440\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8679e-05 - categorical_crossentropy: 3.6130e-04 - acc: 1.0000 - val_loss: 0.3556 - val_categorical_crossentropy: 1.9258 - val_acc: 0.7440\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8556e-05 - categorical_crossentropy: 3.5893e-04 - acc: 1.0000 - val_loss: 0.3557 - val_categorical_crossentropy: 1.9267 - val_acc: 0.7460\n"
     ]
    }
   ],
   "source": [
    "y_train, train_mask = generate_mask_data(whole_labels, train_idx)\n",
    "y_val, val_mask = generate_mask_data(whole_labels, val_idx)\n",
    "y_test, test_mask = generate_mask_data(whole_labels, test_idx)\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(x =  features, \n",
    "                         y = y_train, \n",
    "                         sample_weight= train_mask,\n",
    "                         validation_data=(features, y_val, val_mask),\n",
    "                         batch_size = num_nodes, epochs = 300, \n",
    "                         shuffle = False, \n",
    "                         workers=10, \n",
    "                         use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6964 - categorical_crossentropy: 1.8859 - acc: 0.7420\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate(features, y_test, sample_weight=test_mask, batch_size=num_nodes)"
   ]
  }
 ]
}