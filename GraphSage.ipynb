{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "# tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')"
   ]
  },
  {
   "source": [
    "# Read Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCora():\n",
    "    node_id_map = {}\n",
    "    adj_dict_list = {}\n",
    "    node_label = []\n",
    "    label_id = {}\n",
    "\n",
    "\n",
    "    with open(\"cora/cora.content\",'r') as f:\n",
    "        lines  = f.readlines()\n",
    "        features = []\n",
    "        for idx, line in enumerate(lines):\n",
    "            l = line.strip().split('\\t')\n",
    "            node_feature = list(np.array(l[:-1], dtype = np.float))\n",
    "            node = node_feature[0]\n",
    "            node_id_map[node] = idx\n",
    "            feature = node_feature[1:]\n",
    "            features.append(feature)\n",
    "            label = l[-1]\n",
    "            if label not in label_id:\n",
    "                label_id[label] = len(label_id)\n",
    "            node_label.append(label_id[label])\n",
    "\n",
    "    adj_dict_list = {}\n",
    "    with open(\"cora/cora.cites\", 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            edge = line.strip().split('\\t')\n",
    "            head = node_id_map[float(edge[0])]\n",
    "            tail = node_id_map[float(edge[1])]\n",
    "            if head not in adj_dict_list:\n",
    "                adj_dict_list[head] = set()\n",
    "            if tail not in adj_dict_list:\n",
    "                adj_dict_list[tail] = set()\n",
    "            adj_dict_list[head].add(tail)\n",
    "            adj_dict_list[tail].add(head)\n",
    "    \n",
    "    return features, node_label, label_id, adj_dict_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, node_label, label_id, adj_dict_list = readCora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Neural_Networks': 0, 'Rule_Learning': 1, 'Reinforcement_Learning': 2, 'Probabilistic_Methods': 3, 'Theory': 4, 'Genetic_Algorithms': 5, 'Case_Based': 6}\n"
     ]
    }
   ],
   "source": [
    "print(label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{544, 258, 8, 14, 435}\n"
     ]
    }
   ],
   "source": [
    "print(adj_dict_list[0])  # id 0 --> 31336  : {10531,1129442,31349,686532,31353} --> {258, 544,8,435, 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = 'mean' # {'gcn', 'lstm', 'pooling'}\n",
    "use_gcn = False\n",
    "supervise = True\n",
    "num_nodes = features.shape[0]\n",
    "feature_dim = features.shape[1]\n",
    "num_sample = 10\n",
    "num_class = 7\n",
    "depth = 2\n",
    "seed = 7\n",
    "concat_self = True  # False: inductive 每个节点的特征为其邻居的聚合（不包括自身） True:包括自身\n",
    "embed_dim = 128\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator(keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 output_dims, \n",
    "                 num_samples,\n",
    "                 method = 'mean', \n",
    "                 use_gcn = False, \n",
    "                 dropout = 0., \n",
    "                 activation = keras.activations.relu, \n",
    "                 concat_self = True,\n",
    "                 bilstm = False,\n",
    "                 **kwargs):\n",
    "        super(Aggregator,self).__init__(**kwargs)\n",
    "        self.method = method\n",
    "        self.output_dims = output_dims\n",
    "        self.method = method\n",
    "        self.use_gcn = use_gcn\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "        self.concat_self = concat_self\n",
    "        self.bilstm = bilstm\n",
    "        self.num_samples = num_samples\n",
    "        self.concat = keras.layers.Concatenate()\n",
    "        self.dense = keras.layers.Dense(units=self.output_dims)\n",
    "        self.bilstm = keras.layers.Bidirectional(\n",
    "                    keras.layers.LSTM(units=self.output_dims // 2,\n",
    "                                      stateful = False,\n",
    "                                    #   recurrent_initializer=keras.initializers.GlorotUniform,\n",
    "                                      return_sequences=False)\n",
    "                )\n",
    "        self.lstm = keras.layers.LSTM(units=self.output_dims, \n",
    "                                           stateful=False, \n",
    "                                        #    recurrent_initializer=keras.initializers.GlorotUniform,\n",
    "                                           return_sequences=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Aggregator, self).build(input_shape)\n",
    "        # if self.method == 'mean':\n",
    "        #     if self.use_gcn:\n",
    "        #         self.W = self.add_weight(name = \"weight_gcn\",\n",
    "        #                                  shape = (input_shape[0][1], self.output_dims),\n",
    "        #                                  initializer=keras.initializers.GlorotUniform,\n",
    "        #                                  trainable=True)\n",
    "        #     else:\n",
    "        #         if self.concat_self:\n",
    "        #             self.W = self.add_weight(name = \"weight_mean_concat\",\n",
    "        #                                      shape = (input_shape[0][1] * 2, self.output_dims),\n",
    "        #                                      initializer= keras.initializers.GlorotUniform,\n",
    "        #                                      trainable = True)\n",
    "        #         else:\n",
    "        #             self.W = self.add_weight(name = \"weight_mean\",\n",
    "        #                                      shape = (input_shape[0][1], self.output_dims),\n",
    "        #                                      initializer = keras.initializers.GlorotUniform,\n",
    "        #                                      trainable = True)\n",
    "        # elif self.method == 'lstm':\n",
    "        #     if self.concat_self:\n",
    "        #         self.W = self.add_weight(name = \"weight_lstm_concat\",\n",
    "        #                                        shape = (input_shape[0][1] * 2, self.output_dims),\n",
    "        #                                        initializer= keras.initializers.GlorotUniform,\n",
    "        #                                        trainable = True)\n",
    "        #     else:\n",
    "        #         self.W = self.add_weight(name = \"weight_lstm\",\n",
    "        #                                        shape = (input_shape[0][1], self.output_dims),\n",
    "        #                                        initializer = keras.initializers.GlorotUniform,\n",
    "        #                                        trainable = True)            \n",
    "        # else:  # max pooling\n",
    "        #     if self.concat_self:\n",
    "        #         self.W = self.add_weight(name = \"weight_pool_concat\",\n",
    "        #                                        shape = (input_shape[0][1] * 2, self.output_dims),\n",
    "        #                                        initializer= keras.initializers.GlorotUniform,\n",
    "        #                                        trainable = True)\n",
    "        #     else:\n",
    "        #         self.W = self.add_weight(name = \"weight_pool\",\n",
    "        #                                        shape = (input_shape[0][1], self.output_dims),\n",
    "        #                                        initializer = keras.initializers.GlorotUniform,\n",
    "        #                                        trainable = True)                \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # self_features: (None, 1433)\n",
    "        # neigh_features: [tensor, tensor,......]\n",
    "        self_features, neigh_features = inputs\n",
    "        if self.method == \"mean\":\n",
    "            # self_features = keras.layers.Dropout(self.dropout)(self_features, training = training)  # [[],[],[]]\n",
    "            \n",
    "            if self.use_gcn:\n",
    "                # neigh_features include self\n",
    "                means = tf.stack([tf.reduce_mean(neigh_fea,axis = 0) for neigh_fea in neigh_features])\n",
    "                output = self.dense(means)\n",
    "                # output = tf.matmul(means, self.W)\n",
    "                return self.activation(output)\n",
    "            else:\n",
    "                if self.concat_self:\n",
    "                    ## self_features: [[1,2,3],[4,5,6],[7,8,9]]  3 self node\n",
    "                    ## neigh_features: [[[11,22,33],[44,55,66],[77,66,99]] ,   [[],[]],   [[]]]\n",
    "                    # neigh_means = tf.reduce_mean(neigh_features, axis=1).to_tensor()\n",
    "                    \n",
    "                    neigh_means = tf.stack([tf.reduce_mean(neigh_fea,axis = 0) for neigh_fea in neigh_features])\n",
    "\n",
    "                    # lint 5 in Algorithm 1\n",
    "                    concat = self.concat([self_features, neigh_means])\n",
    "                    # output = tf.matmul(concat, self.W)\n",
    "                    output = self.dense(concat)\n",
    "                else:\n",
    "                    neigh_means = tf.stack([tf.reduce_mean(neigh_fea,axis = 0) for neigh_fea in neigh_features])\n",
    "                    output = self.dense(neigh_means)\n",
    "                    # output = tf.matmul(neigh_means, self.W)\n",
    "                return self.activation(output)\n",
    "        elif self.method == \"lstm\":\n",
    "            if self.concat_self:\n",
    "                to_features = self.concat([self_features, neigh_features])\n",
    "            else:\n",
    "                to_features = neigh_features\n",
    "            \n",
    "            if self.bilstm:\n",
    "                output = self.bilstm(to_features)\n",
    "            else:\n",
    "                output = self.lstm(to_features)\n",
    "            \n",
    "\n",
    "            output = self.dense(output)\n",
    "            # output = tf.matmul(output,self.W)\n",
    "            return self.activation(output)\n",
    "            \n",
    "        else:  # max pooling\n",
    "            if self.concat_self:\n",
    "                to_features = self.concat([self_features, neigh_features])   \n",
    "            else:\n",
    "                to_features = neigh_features\n",
    "            \n",
    "            output = tf.reduce_max(to_features,axis = 1)\n",
    "            output = self.dense(output)\n",
    "            # output = tf.matmul(output,self.W)\n",
    "            return self.activation(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGELayer(keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 adj_list,\n",
    "                 num_nodes, \n",
    "                 embed_dims,\n",
    "                 aggregator = 'mean', \n",
    "                 use_gcn = False,\n",
    "                 num_sample = 5, \n",
    "                 concat = True,\n",
    "                 dropout = 0.,\n",
    "                 seed = 7,\n",
    "                 **kwargs):\n",
    "        super(GraphSAGELayer, self).__init__(**kwargs)\n",
    "        self.adj_list = adj_list\n",
    "        self.aggregator = aggregator\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_sample = num_sample\n",
    "        self.concat = concat\n",
    "        self.use_gcn = use_gcn\n",
    "        self.embed_dims = embed_dims\n",
    "        self.dropout = dropout\n",
    "        self.seed = seed\n",
    "        if self.aggregator == 'mean':\n",
    "            self.agglayer = Aggregator(output_dims = self.embed_dims, \n",
    "                   num_samples = self.num_sample,\n",
    "                   method = self.aggregator, \n",
    "                   use_gcn = self.use_gcn, \n",
    "                   dropout = self.dropout,\n",
    "                   activation=keras.activations.relu, \n",
    "                   concat_self = self.concat)\n",
    "\n",
    "    def _sample_neighbors(self, nodes):\n",
    "        \"\"\"sample neighbors for nodes\"\"\"\n",
    "        neighs = [list(self.adj_list[node]) for node in nodes]\n",
    "        np.random.seed(self.seed)\n",
    "        sampled_neighbor = [list(np.random.choice(neigh, self.num_sample, replace = False)) if len(neigh) >= self.num_sample \n",
    "                                else neigh for neigh in neighs]\n",
    "        if self.aggregator == 'mean' and self.use_gcn:\n",
    "            for i, node in enumerate(nodes):\n",
    "                sampled_neighbor[i].append(node)  # add self to neighborhood\n",
    "\n",
    "        if self.aggregator == 'lstm':\n",
    "            # 打乱节点顺序\n",
    "            np.random.seed(0)\n",
    "            sampled_neighbor = [list(np.random.permutation(neigh)) for neigh in sampled_neighbor]\n",
    "            \n",
    "        return sampled_neighbor\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GraphSAGELayer,self).build(input_shape)\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # 先为每个节点采样邻居 输入为inputs = features\n",
    "        features = inputs  # ndarray  (None,1433)\n",
    "        sampled_neighbors = self._sample_neighbors(np.arange(self.num_nodes))\n",
    "        # sampled_neighbors_mask:\n",
    "        # mask = np.zeros(shape=(self.num_nodes,self.num_nodes),dtype=np.bool)\n",
    "        # for idx, neighs in enumerate(sampled_neighbors):\n",
    "        #     mask[idx][neighs] = True\n",
    "        \n",
    "        # 获取邻居的feature  [tensors , .... ]\n",
    "        # neigh_features = [features[mask[i]] for i in np.arange(self.num_nodes)]\n",
    "\n",
    "        neigh_features = [tf.gather(features, neighs) for neighs in sampled_neighbors]\n",
    "        agg_input = [features, neigh_features]\n",
    "        output = self.agglayer(agg_input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle node and train_test_val split\n",
    "np.random.seed(seed)\n",
    "rand_indices = np.random.permutation(num_nodes)\n",
    "test = rand_indices[:1000]\n",
    "val = rand_indices[1000:1500]\n",
    "train = rand_indices[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 1433)]            0         \n_________________________________________________________________\ngraph_sage_layer (GraphSAGEL (2708, 128)               366976    \n_________________________________________________________________\ngraph_sage_layer_1 (GraphSAG (2708, 7)                 1799      \n=================================================================\nTotal params: 368,775\nTrainable params: 368,775\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2 次迭代\n",
    "input_features = keras.Input(shape = (feature_dim, ))\n",
    "agg1 = GraphSAGELayer(adj_list = adj_dict_list,\n",
    "                      num_nodes = num_nodes, \n",
    "                      embed_dims = embed_dim,\n",
    "                      aggregator = 'mean', \n",
    "                      use_gcn = False)(input_features)                    \n",
    "agg2 = GraphSAGELayer(adj_list = adj_dict_list,\n",
    "                      num_nodes = num_nodes, \n",
    "                      embed_dims = num_class,\n",
    "                      aggregator = 'mean', \n",
    "                      use_gcn = False)(agg1)\n",
    "\n",
    "model = keras.models.Model(inputs = input_features, outputs = agg2)\n",
    "\n",
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Adam(learning_rate=lr),\n",
    "              weighted_metrics=['sparse_categorical_crossentropy', 'acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_crossentropy: 1.4057 - acc: 0.2997 - val_loss: 0.2768 - val_sparse_categorical_crossentropy: 1.4989 - val_acc: 0.3080\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6141 - sparse_categorical_crossentropy: 1.3766 - acc: 0.3005WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6141 - sparse_categorical_crossentropy: 1.3766 - acc: 0.3005 - val_loss: 0.2811 - val_sparse_categorical_crossentropy: 1.5223 - val_acc: 0.3080\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5997 - sparse_categorical_crossentropy: 1.3444 - acc: 0.3005WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5997 - sparse_categorical_crossentropy: 1.3444 - acc: 0.3005 - val_loss: 0.2749 - val_sparse_categorical_crossentropy: 1.4888 - val_acc: 0.3080\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5816 - sparse_categorical_crossentropy: 1.3037 - acc: 0.3005WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.5816 - sparse_categorical_crossentropy: 1.3037 - acc: 0.3005 - val_loss: 0.2620 - val_sparse_categorical_crossentropy: 1.4188 - val_acc: 0.3080\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5594 - sparse_categorical_crossentropy: 1.2540 - acc: 0.3005WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.5594 - sparse_categorical_crossentropy: 1.2540 - acc: 0.3005 - val_loss: 0.2474 - val_sparse_categorical_crossentropy: 1.3401 - val_acc: 0.3080\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5350 - sparse_categorical_crossentropy: 1.1993 - acc: 0.3013WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5350 - sparse_categorical_crossentropy: 1.1993 - acc: 0.3013 - val_loss: 0.2412 - val_sparse_categorical_crossentropy: 1.3066 - val_acc: 0.3100\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5103 - sparse_categorical_crossentropy: 1.1439 - acc: 0.3030WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5103 - sparse_categorical_crossentropy: 1.1439 - acc: 0.3030 - val_loss: 0.2315 - val_sparse_categorical_crossentropy: 1.2537 - val_acc: 0.3120\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4863 - sparse_categorical_crossentropy: 1.0902 - acc: 0.3088WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.4863 - sparse_categorical_crossentropy: 1.0902 - acc: 0.3088 - val_loss: 0.2232 - val_sparse_categorical_crossentropy: 1.2091 - val_acc: 0.3160\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4642 - sparse_categorical_crossentropy: 1.0406 - acc: 0.3195WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.4642 - sparse_categorical_crossentropy: 1.0406 - acc: 0.3195 - val_loss: 0.2209 - val_sparse_categorical_crossentropy: 1.1965 - val_acc: 0.3340\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4457 - sparse_categorical_crossentropy: 0.9991 - acc: 0.3320WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.4457 - sparse_categorical_crossentropy: 0.9991 - acc: 0.3320 - val_loss: 0.2168 - val_sparse_categorical_crossentropy: 1.1744 - val_acc: 0.3540\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4306 - sparse_categorical_crossentropy: 0.9652 - acc: 0.3535WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.4306 - sparse_categorical_crossentropy: 0.9652 - acc: 0.3535 - val_loss: 0.2172 - val_sparse_categorical_crossentropy: 1.1761 - val_acc: 0.3720\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4169 - sparse_categorical_crossentropy: 0.9345 - acc: 0.3758WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.4169 - sparse_categorical_crossentropy: 0.9345 - acc: 0.3758 - val_loss: 0.2166 - val_sparse_categorical_crossentropy: 1.1733 - val_acc: 0.3880\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4013 - sparse_categorical_crossentropy: 0.8996 - acc: 0.3957WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.4013 - sparse_categorical_crossentropy: 0.8996 - acc: 0.3957 - val_loss: 0.2103 - val_sparse_categorical_crossentropy: 1.1387 - val_acc: 0.4000\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3824 - sparse_categorical_crossentropy: 0.8572 - acc: 0.4123WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3824 - sparse_categorical_crossentropy: 0.8572 - acc: 0.4123 - val_loss: 0.2036 - val_sparse_categorical_crossentropy: 1.1027 - val_acc: 0.4100\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3619 - sparse_categorical_crossentropy: 0.8113 - acc: 0.4305WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3619 - sparse_categorical_crossentropy: 0.8113 - acc: 0.4305 - val_loss: 0.2077 - val_sparse_categorical_crossentropy: 1.1247 - val_acc: 0.4320\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3422 - sparse_categorical_crossentropy: 0.7671 - acc: 0.4594WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3422 - sparse_categorical_crossentropy: 0.7671 - acc: 0.4594 - val_loss: 0.2005 - val_sparse_categorical_crossentropy: 1.0857 - val_acc: 0.4480\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3242 - sparse_categorical_crossentropy: 0.7267 - acc: 0.5000WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3242 - sparse_categorical_crossentropy: 0.7267 - acc: 0.5000 - val_loss: 0.1930 - val_sparse_categorical_crossentropy: 1.0450 - val_acc: 0.4840\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3074 - sparse_categorical_crossentropy: 0.6891 - acc: 0.5505WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3074 - sparse_categorical_crossentropy: 0.6891 - acc: 0.5505 - val_loss: 0.1861 - val_sparse_categorical_crossentropy: 1.0078 - val_acc: 0.5320\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2913 - sparse_categorical_crossentropy: 0.6530 - acc: 0.6109WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.2913 - sparse_categorical_crossentropy: 0.6530 - acc: 0.6109 - val_loss: 0.1796 - val_sparse_categorical_crossentropy: 0.9725 - val_acc: 0.5840\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2754 - sparse_categorical_crossentropy: 0.6173 - acc: 0.6854WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.2754 - sparse_categorical_crossentropy: 0.6173 - acc: 0.6854 - val_loss: 0.1693 - val_sparse_categorical_crossentropy: 0.9172 - val_acc: 0.6420\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2592 - sparse_categorical_crossentropy: 0.5811 - acc: 0.7442WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.2592 - sparse_categorical_crossentropy: 0.5811 - acc: 0.7442 - val_loss: 0.1627 - val_sparse_categorical_crossentropy: 0.8814 - val_acc: 0.7020\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2428 - sparse_categorical_crossentropy: 0.5442 - acc: 0.8063WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.2428 - sparse_categorical_crossentropy: 0.5442 - acc: 0.8063 - val_loss: 0.1564 - val_sparse_categorical_crossentropy: 0.8468 - val_acc: 0.7460\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2259 - sparse_categorical_crossentropy: 0.5065 - acc: 0.8444WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2259 - sparse_categorical_crossentropy: 0.5065 - acc: 0.8444 - val_loss: 0.1501 - val_sparse_categorical_crossentropy: 0.8129 - val_acc: 0.7920\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2088 - sparse_categorical_crossentropy: 0.4681 - acc: 0.8742WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2088 - sparse_categorical_crossentropy: 0.4681 - acc: 0.8742 - val_loss: 0.1438 - val_sparse_categorical_crossentropy: 0.7787 - val_acc: 0.8180\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1911 - sparse_categorical_crossentropy: 0.4284 - acc: 0.9089WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1911 - sparse_categorical_crossentropy: 0.4284 - acc: 0.9089 - val_loss: 0.1373 - val_sparse_categorical_crossentropy: 0.7435 - val_acc: 0.8340\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1726 - sparse_categorical_crossentropy: 0.3868 - acc: 0.9230WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.1726 - sparse_categorical_crossentropy: 0.3868 - acc: 0.9230 - val_loss: 0.1307 - val_sparse_categorical_crossentropy: 0.7079 - val_acc: 0.8360\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1529 - sparse_categorical_crossentropy: 0.3427 - acc: 0.9305WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1529 - sparse_categorical_crossentropy: 0.3427 - acc: 0.9305 - val_loss: 0.1282 - val_sparse_categorical_crossentropy: 0.6945 - val_acc: 0.8420\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1316 - sparse_categorical_crossentropy: 0.2951 - acc: 0.9387WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1316 - sparse_categorical_crossentropy: 0.2951 - acc: 0.9387 - val_loss: 0.1405 - val_sparse_categorical_crossentropy: 0.7609 - val_acc: 0.8520\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1084 - sparse_categorical_crossentropy: 0.2430 - acc: 0.9363WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1084 - sparse_categorical_crossentropy: 0.2430 - acc: 0.9363 - val_loss: 0.1503 - val_sparse_categorical_crossentropy: 0.8138 - val_acc: 0.8520\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0861 - sparse_categorical_crossentropy: 0.1930 - acc: 0.9321WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0861 - sparse_categorical_crossentropy: 0.1930 - acc: 0.9321 - val_loss: 0.1677 - val_sparse_categorical_crossentropy: 0.9081 - val_acc: 0.8520\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0852 - sparse_categorical_crossentropy: 0.1909 - acc: 0.9280WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0852 - sparse_categorical_crossentropy: 0.1909 - acc: 0.9280 - val_loss: 0.2010 - val_sparse_categorical_crossentropy: 1.0887 - val_acc: 0.8440\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1085 - sparse_categorical_crossentropy: 0.2433 - acc: 0.9305WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.1085 - sparse_categorical_crossentropy: 0.2433 - acc: 0.9305 - val_loss: 0.2369 - val_sparse_categorical_crossentropy: 1.2832 - val_acc: 0.8520\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0960 - sparse_categorical_crossentropy: 0.2153 - acc: 0.9321WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0960 - sparse_categorical_crossentropy: 0.2153 - acc: 0.9321 - val_loss: 0.2327 - val_sparse_categorical_crossentropy: 1.2604 - val_acc: 0.8520\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0813 - sparse_categorical_crossentropy: 0.1824 - acc: 0.9396WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0813 - sparse_categorical_crossentropy: 0.1824 - acc: 0.9396 - val_loss: 0.2307 - val_sparse_categorical_crossentropy: 1.2492 - val_acc: 0.8580\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0650 - sparse_categorical_crossentropy: 0.1458 - acc: 0.9545WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0650 - sparse_categorical_crossentropy: 0.1458 - acc: 0.9545 - val_loss: 0.2367 - val_sparse_categorical_crossentropy: 1.2822 - val_acc: 0.8620\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0540 - sparse_categorical_crossentropy: 0.1209 - acc: 0.9586WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0540 - sparse_categorical_crossentropy: 0.1209 - acc: 0.9586 - val_loss: 0.2399 - val_sparse_categorical_crossentropy: 1.2991 - val_acc: 0.8540\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0509 - sparse_categorical_crossentropy: 0.1142 - acc: 0.9644WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0509 - sparse_categorical_crossentropy: 0.1142 - acc: 0.9644 - val_loss: 0.2443 - val_sparse_categorical_crossentropy: 1.3234 - val_acc: 0.8560\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0390 - sparse_categorical_crossentropy: 0.0874 - acc: 0.9685WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0390 - sparse_categorical_crossentropy: 0.0874 - acc: 0.9685 - val_loss: 0.2483 - val_sparse_categorical_crossentropy: 1.3450 - val_acc: 0.8540\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0296 - sparse_categorical_crossentropy: 0.0664 - acc: 0.9743WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0296 - sparse_categorical_crossentropy: 0.0664 - acc: 0.9743 - val_loss: 0.2745 - val_sparse_categorical_crossentropy: 1.4864 - val_acc: 0.8480\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0312 - sparse_categorical_crossentropy: 0.0699 - acc: 0.9669WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0312 - sparse_categorical_crossentropy: 0.0699 - acc: 0.9669 - val_loss: 0.2860 - val_sparse_categorical_crossentropy: 1.5491 - val_acc: 0.8440\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0389 - sparse_categorical_crossentropy: 0.0872 - acc: 0.9661WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0389 - sparse_categorical_crossentropy: 0.0872 - acc: 0.9661 - val_loss: 0.2811 - val_sparse_categorical_crossentropy: 1.5225 - val_acc: 0.8360\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0470 - sparse_categorical_crossentropy: 0.1054 - acc: 0.9627WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0470 - sparse_categorical_crossentropy: 0.1054 - acc: 0.9627 - val_loss: 0.2731 - val_sparse_categorical_crossentropy: 1.4790 - val_acc: 0.8240\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0472 - sparse_categorical_crossentropy: 0.1058 - acc: 0.9636WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0472 - sparse_categorical_crossentropy: 0.1058 - acc: 0.9636 - val_loss: 0.2703 - val_sparse_categorical_crossentropy: 1.4638 - val_acc: 0.8200\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0438 - sparse_categorical_crossentropy: 0.0982 - acc: 0.9661WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0438 - sparse_categorical_crossentropy: 0.0982 - acc: 0.9661 - val_loss: 0.2475 - val_sparse_categorical_crossentropy: 1.3403 - val_acc: 0.8300\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0352 - sparse_categorical_crossentropy: 0.0789 - acc: 0.9710WARNING:tensorflow:Can save best model only with val_weighted_sparse_categorical_crossentropy available, skipping.\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0352 - sparse_categorical_crossentropy: 0.0789 - acc: 0.9710 - val_loss: 0.2471 - val_sparse_categorical_crossentropy: 1.3383 - val_acc: 0.8380\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "callback = [keras.callbacks.ModelCheckpoint('./best_model.h5',\n",
    "                                            monitor='val_weighted_sparse_categorical_crossentropy',\n",
    "                                            save_best_only=True,\n",
    "                                            save_weights_only=True), \n",
    "              keras.callbacks.EarlyStopping(monitor=\"val_acc\",\n",
    "              min_delta=1e-4, patience=10)]\n",
    "\n",
    "\n",
    "print(\"start training\")\n",
    "node_labels = np.array(node_label)\n",
    "def sample_mask(idx, l):\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "y_train = np.zeros(node_labels.shape)\n",
    "train_mask = sample_mask(train, node_labels.shape[0])\n",
    "y_train[train_mask] = node_labels[train_mask]\n",
    "\n",
    "y_val = np.zeros(node_labels.shape)\n",
    "val_mask = sample_mask(val, node_labels.shape[0])\n",
    "y_val[val_mask] = node_labels[val_mask]\n",
    "\n",
    "y_test = np.zeros(node_labels.shape)\n",
    "test_mask = sample_mask(test, node_labels.shape[0])\n",
    "y_test[test_mask] = node_labels[test_mask]\n",
    "\n",
    "def preprocess_features(features):\n",
    "    row_sum = np.array(features.sum(1))\n",
    "    reverse_row_sum = np.power(row_sum,-1).flatten()\n",
    "    reverse_row_sum[np.isinf(reverse_row_sum)] = 0.\n",
    "    new_features = sp.diags(reverse_row_sum).dot(features)\n",
    "    return new_features\n",
    "features_ = preprocess_features(features)\n",
    "\n",
    "history = model.fit(x=features_, y = y_train, sample_weight= train_mask, validation_data=(features_, y_val, val_mask),\n",
    "                    batch_size = num_nodes, epochs = 150, shuffle = False, workers=10, use_multiprocessing=True,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4672 - sparse_categorical_crossentropy: 1.2653 - acc: 0.8440\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate(features_, y_test, sample_weight=test_mask, batch_size=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}