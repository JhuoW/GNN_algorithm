{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import DataLoader, Dataset, InMemoryDataset, download_url, extract_zip\n",
    "from torch_geometric.nn import dense_diff_pool, GCNConv, GraphConv, SAGPooling, global_mean_pool, global_max_pool \n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import time\n",
    "from torch_geometric.io import read_tu_data\n",
    "from tu_dataset import TUDataset\n",
    "# from torch_geometric.datasets import TUDataset\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(777)\n",
    "else:\n",
    "    torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(data, index):\n",
    "    data.x = F.normalize(data.x, p=2,dim = -1)   # L_2归一化\n",
    "    data.i = index\n",
    "    return data\n",
    "DD = TUDataset(root='datasets/DD',name='DD', pre_transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = DD.num_classes\n",
    "num_features = DD.num_features\n",
    "num_graphs = len(DD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "num_train = int(num_graphs*0.8)\n",
    "num_val = int(num_graphs*0.1)\n",
    "num_test = num_graphs - (num_train+num_val)\n",
    "training_set, validation_set, testing_set = random_split(DD, [num_train, num_val, num_test])\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size= batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validation_set,batch_size = batch_size, shuffle=False)\n",
    "test_loader = DataLoader(testing_set,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5748\n"
     ]
    }
   ],
   "source": [
    "max_node = np.max([x.num_nodes for x in DD])\n",
    "# learning_rate = 0.001\n",
    "reg = 0.0001\n",
    "epochs = 300\n",
    "num_hidden = 128\n",
    "pooling_ratio = .8\n",
    "dropout_ratio = .5\n",
    "print(max_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, num_hid, num_classes, pooling_ratio, dropout_ratio, score_conv = GCNConv):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.num_hid = num_hid\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        \n",
    "        self.conv1 = GCNConv(num_features, num_hid)\n",
    "        self.pool1 = SAGPooling(num_hid, ratio=pooling_ratio, GNN = score_conv)\n",
    "\n",
    "        self.conv2 = GCNConv(num_hid, num_hid)\n",
    "        self.pool2 = SAGPooling(num_hid,ratio=pooling_ratio, GNN = GCNConv)\n",
    "\n",
    "        self.conv3 = GCNConv(num_hid, num_hid)\n",
    "        self.pool3 = SAGPooling(num_hid,ratio=pooling_ratio, GNN = GCNConv)\n",
    "\n",
    "        self.linear1 = nn.Linear(num_hid * 2, num_hid)\n",
    "        self.linear2 = nn.Linear(num_hid, num_hid //2)\n",
    "        self.linear3 = nn.Linear(num_hid//2, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Batch(batch=[35631], edge_index=[2, 179034], i=[128], x=[35631, 89], y=[128])\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _,_ = self.pool1(x, edge_index, batch = batch)\n",
    "        x1 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _ ,_= self.pool2(x, edge_index,batch = batch)\n",
    "        x2 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _,_ = self.pool3(x, edge_index, batch = batch)\n",
    "        x3 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.dropout(x, p=self.dropout_ratio, training=self.training)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, labels):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(output, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n  (conv1): GCNConv(89, 128)\n  (pool1): SAGPooling(GCNConv, 128, ratio=0.8, multiplier=1)\n  (conv2): GCNConv(128, 128)\n  (pool2): SAGPooling(GCNConv, 128, ratio=0.8, multiplier=1)\n  (conv3): GCNConv(128, 128)\n  (pool3): SAGPooling(GCNConv, 128, ratio=0.8, multiplier=1)\n  (linear1): Linear(in_features=256, out_features=128, bias=True)\n  (linear2): Linear(in_features=128, out_features=64, bias=True)\n  (linear3): Linear(in_features=64, out_features=2, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "model = Net(num_features,num_hidden,num_classes, pooling_ratio, dropout_ratio)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=reg)\n",
    "print(model)"
   ]
  },
  {
   "source": [
    "### Early Stopping Function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 0\n",
    "limit_patience = 50\n",
    "min_loss = float(\"inf\")\n",
    "def early_stopping(val_loss, min_loss, epoch, dataset=\"DD\" , method = \"SAGPool\"):\n",
    "    if val_loss < min_loss:\n",
    "        torch.save(model.state_dict(), 'saved_model_{}_{}.pth'.format(dataset, method))\n",
    "        # print(\"model saved at epoch {}\".format(epoch))\n",
    "        min_loss = val_loss\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "    return patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(output, data.y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc += torch.eq(torch.argmax(output, -1),data.y).sum().item()\n",
    "\n",
    "    acc_current_epoch = train_acc / len(loader.dataset)\n",
    "    return train_loss, acc_current_epoch\n",
    "\n",
    "\n",
    "def val(loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(output, data.y)\n",
    "        correct += torch.eq(torch.argmax(output,-1),data.y).sum().item()\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "\n",
    "    val_acc_epoch = correct / len(loader.dataset)\n",
    "    return val_loss, val_acc_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training():\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, acc_current_epoch = train(train_loader)\n",
    "        val_loss, val_acc_epoch = val(val_loader)\n",
    "        print(\"Epochs:{} Train loss:{} Train accuracy:{} Validation loss:{} Validation accuracy:{}\".format(epoch, train_loss, acc_current_epoch, val_loss, val_acc_epoch))\n",
    "        patience = early_stopping(val_loss, min_loss, epoch)\n",
    "\n",
    "        if patience > limit_patience:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "on accuracy:0.8290598290598291\n",
      "Epochs:166 Train loss:0.5807328429073095 Train accuracy:0.9851380042462845 Validation loss:0.8404719829559326 Validation accuracy:0.8205128205128205\n",
      "Epochs:167 Train loss:0.6125918552279472 Train accuracy:0.9787685774946921 Validation loss:1.0166735649108887 Validation accuracy:0.8376068376068376\n",
      "Epochs:168 Train loss:0.60365847684443 Train accuracy:0.9830148619957537 Validation loss:0.9318631291389465 Validation accuracy:0.811965811965812\n",
      "Epochs:169 Train loss:0.46387396566569805 Train accuracy:0.9872611464968153 Validation loss:0.9437280893325806 Validation accuracy:0.811965811965812\n",
      "Epochs:170 Train loss:0.4949536882340908 Train accuracy:0.9872611464968153 Validation loss:1.0321846008300781 Validation accuracy:0.811965811965812\n",
      "Epochs:171 Train loss:0.4562909146770835 Train accuracy:0.9872611464968153 Validation loss:1.0456277132034302 Validation accuracy:0.8290598290598291\n",
      "Epochs:172 Train loss:0.4178936704993248 Train accuracy:0.9851380042462845 Validation loss:1.1215325593948364 Validation accuracy:0.8376068376068376\n",
      "Epochs:173 Train loss:0.4900522083044052 Train accuracy:0.9851380042462845 Validation loss:1.0914063453674316 Validation accuracy:0.8290598290598291\n",
      "Epochs:174 Train loss:0.46605145931243896 Train accuracy:0.9851380042462845 Validation loss:1.0212557315826416 Validation accuracy:0.7948717948717948\n",
      "Epochs:175 Train loss:0.45902456529438496 Train accuracy:0.9861995753715499 Validation loss:0.9712031483650208 Validation accuracy:0.7948717948717948\n",
      "Epochs:176 Train loss:0.47007762640714645 Train accuracy:0.9830148619957537 Validation loss:1.102342963218689 Validation accuracy:0.8205128205128205\n",
      "Epochs:177 Train loss:0.45969116501510143 Train accuracy:0.9861995753715499 Validation loss:1.121412992477417 Validation accuracy:0.811965811965812\n",
      "Epochs:178 Train loss:0.4199466407299042 Train accuracy:0.9872611464968153 Validation loss:1.1407462358474731 Validation accuracy:0.811965811965812\n",
      "Epochs:179 Train loss:0.3457683678716421 Train accuracy:0.9883227176220807 Validation loss:1.1228941679000854 Validation accuracy:0.7948717948717948\n",
      "Epochs:180 Train loss:0.3603227995336056 Train accuracy:0.9883227176220807 Validation loss:1.0784521102905273 Validation accuracy:0.7948717948717948\n",
      "Epochs:181 Train loss:0.394064087420702 Train accuracy:0.9872611464968153 Validation loss:1.1364508867263794 Validation accuracy:0.8034188034188035\n",
      "Epochs:182 Train loss:0.3732373248785734 Train accuracy:0.9872611464968153 Validation loss:1.148342251777649 Validation accuracy:0.811965811965812\n",
      "Epochs:183 Train loss:0.39505454152822495 Train accuracy:0.9861995753715499 Validation loss:1.3739300966262817 Validation accuracy:0.8205128205128205\n",
      "Epochs:184 Train loss:0.43202437832951546 Train accuracy:0.9851380042462845 Validation loss:1.2162131071090698 Validation accuracy:0.8205128205128205\n",
      "Epochs:185 Train loss:0.42252012342214584 Train accuracy:0.9904458598726115 Validation loss:1.1888574361801147 Validation accuracy:0.8034188034188035\n",
      "Epochs:186 Train loss:0.37730458192527294 Train accuracy:0.9904458598726115 Validation loss:1.1999335289001465 Validation accuracy:0.7948717948717948\n",
      "Epochs:187 Train loss:0.31464756932109594 Train accuracy:0.9904458598726115 Validation loss:1.2954367399215698 Validation accuracy:0.811965811965812\n",
      "Epochs:188 Train loss:0.36908523086458445 Train accuracy:0.9904458598726115 Validation loss:1.3263580799102783 Validation accuracy:0.8290598290598291\n",
      "Epochs:189 Train loss:0.3905725246295333 Train accuracy:0.9883227176220807 Validation loss:1.266117811203003 Validation accuracy:0.811965811965812\n",
      "Epochs:190 Train loss:0.3093059463426471 Train accuracy:0.9904458598726115 Validation loss:1.2216604948043823 Validation accuracy:0.7863247863247863\n",
      "Epochs:191 Train loss:0.2960711941123009 Train accuracy:0.9915074309978769 Validation loss:1.2164037227630615 Validation accuracy:0.7863247863247863\n",
      "Epochs:192 Train loss:0.3865690268576145 Train accuracy:0.9893842887473461 Validation loss:1.1648553609848022 Validation accuracy:0.7863247863247863\n",
      "Epochs:193 Train loss:0.3382728174328804 Train accuracy:0.9915074309978769 Validation loss:1.208221197128296 Validation accuracy:0.811965811965812\n",
      "Epochs:194 Train loss:0.2848178241401911 Train accuracy:0.9915074309978769 Validation loss:1.3160717487335205 Validation accuracy:0.811965811965812\n",
      "Epochs:195 Train loss:0.3353146696463227 Train accuracy:0.9915074309978769 Validation loss:1.3204989433288574 Validation accuracy:0.811965811965812\n",
      "Epochs:196 Train loss:0.307823303155601 Train accuracy:0.9915074309978769 Validation loss:1.294446349143982 Validation accuracy:0.811965811965812\n",
      "Epochs:197 Train loss:0.2601062571629882 Train accuracy:0.9915074309978769 Validation loss:1.3169161081314087 Validation accuracy:0.8034188034188035\n",
      "Epochs:198 Train loss:0.2511936379596591 Train accuracy:0.9915074309978769 Validation loss:1.3557173013687134 Validation accuracy:0.7948717948717948\n",
      "Epochs:199 Train loss:0.24222073704004288 Train accuracy:0.9904458598726115 Validation loss:1.3289400339126587 Validation accuracy:0.811965811965812\n",
      "Epochs:200 Train loss:0.25765067897737026 Train accuracy:0.9915074309978769 Validation loss:1.3940296173095703 Validation accuracy:0.8034188034188035\n",
      "Epochs:201 Train loss:0.22485916316509247 Train accuracy:0.9904458598726115 Validation loss:1.4575847387313843 Validation accuracy:0.811965811965812\n",
      "Epochs:202 Train loss:0.23122985800728202 Train accuracy:0.9904458598726115 Validation loss:1.3973137140274048 Validation accuracy:0.7863247863247863\n",
      "Epochs:203 Train loss:0.2310340804979205 Train accuracy:0.9915074309978769 Validation loss:1.403743863105774 Validation accuracy:0.7863247863247863\n",
      "Epochs:204 Train loss:0.25147647596895695 Train accuracy:0.9915074309978769 Validation loss:1.4627326726913452 Validation accuracy:0.7948717948717948\n",
      "Epochs:205 Train loss:0.28768779477104545 Train accuracy:0.9915074309978769 Validation loss:1.4245498180389404 Validation accuracy:0.8034188034188035\n",
      "Epochs:206 Train loss:0.2621838944032788 Train accuracy:0.9915074309978769 Validation loss:1.358436942100525 Validation accuracy:0.7948717948717948\n",
      "Epochs:207 Train loss:0.23428702866658568 Train accuracy:0.9915074309978769 Validation loss:1.4573793411254883 Validation accuracy:0.7948717948717948\n",
      "Epochs:208 Train loss:0.20779509330168366 Train accuracy:0.9915074309978769 Validation loss:1.4187932014465332 Validation accuracy:0.7948717948717948\n",
      "Epochs:209 Train loss:0.24230079678818583 Train accuracy:0.9915074309978769 Validation loss:1.4001544713974 Validation accuracy:0.7863247863247863\n",
      "Epochs:210 Train loss:0.19946044124662876 Train accuracy:0.9915074309978769 Validation loss:1.3988919258117676 Validation accuracy:0.7948717948717948\n",
      "Epochs:211 Train loss:0.2753767501562834 Train accuracy:0.9904458598726115 Validation loss:1.5131477117538452 Validation accuracy:0.8034188034188035\n",
      "Epochs:212 Train loss:0.23138541169464588 Train accuracy:0.9904458598726115 Validation loss:1.5562533140182495 Validation accuracy:0.811965811965812\n",
      "Epochs:213 Train loss:0.22725061140954494 Train accuracy:0.9893842887473461 Validation loss:1.7622015476226807 Validation accuracy:0.811965811965812\n",
      "Epochs:214 Train loss:0.275733046233654 Train accuracy:0.9883227176220807 Validation loss:1.4289209842681885 Validation accuracy:0.7948717948717948\n",
      "Epochs:215 Train loss:0.19332553539425135 Train accuracy:0.9925690021231423 Validation loss:1.4577163457870483 Validation accuracy:0.7777777777777778\n",
      "Epochs:216 Train loss:0.18109227949753404 Train accuracy:0.9925690021231423 Validation loss:1.4885331392288208 Validation accuracy:0.7777777777777778\n",
      "Epochs:217 Train loss:0.1958006927743554 Train accuracy:0.9915074309978769 Validation loss:1.5726537704467773 Validation accuracy:0.811965811965812\n",
      "Epochs:218 Train loss:0.260558707639575 Train accuracy:0.9893842887473461 Validation loss:1.4456651210784912 Validation accuracy:0.7606837606837606\n",
      "Epochs:219 Train loss:0.955773526802659 Train accuracy:0.9575371549893843 Validation loss:1.2996526956558228 Validation accuracy:0.717948717948718\n",
      "Epochs:220 Train loss:2.196627177298069 Train accuracy:0.8959660297239915 Validation loss:0.9958224892616272 Validation accuracy:0.8205128205128205\n",
      "Epochs:221 Train loss:1.7065583691000938 Train accuracy:0.9129511677282378 Validation loss:0.7928163409233093 Validation accuracy:0.7863247863247863\n",
      "Epochs:222 Train loss:0.8948136530816555 Train accuracy:0.9628450106157113 Validation loss:0.9140129685401917 Validation accuracy:0.8034188034188035\n",
      "Epochs:223 Train loss:0.6573541648685932 Train accuracy:0.9787685774946921 Validation loss:1.2593454122543335 Validation accuracy:0.7948717948717948\n",
      "Epochs:224 Train loss:0.5516355019062757 Train accuracy:0.9787685774946921 Validation loss:1.1136263608932495 Validation accuracy:0.811965811965812\n",
      "Epochs:225 Train loss:0.3939406778663397 Train accuracy:0.9883227176220807 Validation loss:1.221337914466858 Validation accuracy:0.811965811965812\n",
      "Epochs:226 Train loss:0.37357656843960285 Train accuracy:0.9872611464968153 Validation loss:1.2331547737121582 Validation accuracy:0.811965811965812\n",
      "Epochs:227 Train loss:0.2827673740684986 Train accuracy:0.9915074309978769 Validation loss:1.170525074005127 Validation accuracy:0.7863247863247863\n",
      "Epochs:228 Train loss:0.2601129626855254 Train accuracy:0.9915074309978769 Validation loss:1.2709583044052124 Validation accuracy:0.7948717948717948\n",
      "Epochs:229 Train loss:0.23386993445456028 Train accuracy:0.9915074309978769 Validation loss:1.2591650485992432 Validation accuracy:0.7863247863247863\n",
      "Epochs:230 Train loss:0.20911261346191168 Train accuracy:0.9925690021231423 Validation loss:1.3071709871292114 Validation accuracy:0.7948717948717948\n",
      "Epochs:231 Train loss:0.19854007242247462 Train accuracy:0.9925690021231423 Validation loss:1.36356782913208 Validation accuracy:0.7948717948717948\n",
      "Epochs:232 Train loss:0.19361719908192754 Train accuracy:0.9925690021231423 Validation loss:1.370053768157959 Validation accuracy:0.7948717948717948\n",
      "Epochs:233 Train loss:0.18477295571938157 Train accuracy:0.9925690021231423 Validation loss:1.3540841341018677 Validation accuracy:0.7948717948717948\n",
      "Epochs:234 Train loss:0.20766163151711226 Train accuracy:0.9925690021231423 Validation loss:1.4075446128845215 Validation accuracy:0.7948717948717948\n",
      "Epochs:235 Train loss:0.17405979055911303 Train accuracy:0.9925690021231423 Validation loss:1.4413156509399414 Validation accuracy:0.7863247863247863\n",
      "Epochs:236 Train loss:0.17941305553540587 Train accuracy:0.9915074309978769 Validation loss:1.3651806116104126 Validation accuracy:0.7863247863247863\n",
      "Epochs:237 Train loss:0.17704174295067787 Train accuracy:0.9925690021231423 Validation loss:1.398943543434143 Validation accuracy:0.7777777777777778\n",
      "Epochs:238 Train loss:0.1878102170303464 Train accuracy:0.9925690021231423 Validation loss:1.4753037691116333 Validation accuracy:0.7948717948717948\n",
      "Epochs:239 Train loss:0.19500652886927128 Train accuracy:0.9925690021231423 Validation loss:1.4592446088790894 Validation accuracy:0.7948717948717948\n",
      "Epochs:240 Train loss:0.19034366123378277 Train accuracy:0.9925690021231423 Validation loss:1.400071144104004 Validation accuracy:0.7777777777777778\n",
      "Epochs:241 Train loss:0.15612061647698283 Train accuracy:0.9925690021231423 Validation loss:1.5397287607192993 Validation accuracy:0.7948717948717948\n",
      "Epochs:242 Train loss:0.1692487478721887 Train accuracy:0.9915074309978769 Validation loss:1.6198331117630005 Validation accuracy:0.811965811965812\n",
      "Epochs:243 Train loss:0.15958790155127645 Train accuracy:0.9925690021231423 Validation loss:1.5499286651611328 Validation accuracy:0.7948717948717948\n",
      "Epochs:244 Train loss:0.15004891995340586 Train accuracy:0.9925690021231423 Validation loss:1.448809266090393 Validation accuracy:0.8034188034188035\n",
      "Epochs:245 Train loss:0.20255677169188857 Train accuracy:0.9925690021231423 Validation loss:1.6111042499542236 Validation accuracy:0.7948717948717948\n",
      "Epochs:246 Train loss:0.14394470117986202 Train accuracy:0.9925690021231423 Validation loss:1.512662649154663 Validation accuracy:0.7863247863247863\n",
      "Epochs:247 Train loss:0.18815315747633576 Train accuracy:0.9915074309978769 Validation loss:1.7791812419891357 Validation accuracy:0.8034188034188035\n",
      "Epochs:248 Train loss:0.6078123673796654 Train accuracy:0.9798301486199575 Validation loss:1.4223593473434448 Validation accuracy:0.6581196581196581\n",
      "Epochs:249 Train loss:2.279207780957222 Train accuracy:0.8895966029723992 Validation loss:1.280997395515442 Validation accuracy:0.7435897435897436\n",
      "Epochs:250 Train loss:1.0858138129115105 Train accuracy:0.9447983014861996 Validation loss:1.0596001148223877 Validation accuracy:0.7948717948717948\n",
      "Epochs:251 Train loss:0.7746466174721718 Train accuracy:0.9723991507430998 Validation loss:1.0586153268814087 Validation accuracy:0.7863247863247863\n",
      "Epochs:252 Train loss:0.4473985359072685 Train accuracy:0.9808917197452229 Validation loss:1.06061589717865 Validation accuracy:0.7863247863247863\n",
      "Epochs:253 Train loss:0.4054735265672207 Train accuracy:0.9840764331210191 Validation loss:1.120050311088562 Validation accuracy:0.7777777777777778\n",
      "Epochs:254 Train loss:0.3680656347423792 Train accuracy:0.9893842887473461 Validation loss:1.2111448049545288 Validation accuracy:0.7863247863247863\n",
      "Epochs:255 Train loss:0.2541324608027935 Train accuracy:0.9915074309978769 Validation loss:1.283969759941101 Validation accuracy:0.8034188034188035\n",
      "Epochs:256 Train loss:0.26427741814404726 Train accuracy:0.9904458598726115 Validation loss:1.2841649055480957 Validation accuracy:0.7777777777777778\n",
      "Epochs:257 Train loss:0.25863715540617704 Train accuracy:0.9893842887473461 Validation loss:1.2177706956863403 Validation accuracy:0.7692307692307693\n",
      "Epochs:258 Train loss:0.2135238377377391 Train accuracy:0.9925690021231423 Validation loss:1.3234859704971313 Validation accuracy:0.7863247863247863\n",
      "Epochs:259 Train loss:0.21346556022763252 Train accuracy:0.9915074309978769 Validation loss:1.4167274236679077 Validation accuracy:0.8034188034188035\n",
      "Epochs:260 Train loss:0.18287355080246925 Train accuracy:0.9925690021231423 Validation loss:1.2629473209381104 Validation accuracy:0.7863247863247863\n",
      "Epochs:261 Train loss:0.24745840020477772 Train accuracy:0.9893842887473461 Validation loss:1.275792121887207 Validation accuracy:0.7948717948717948\n",
      "Epochs:262 Train loss:0.175067531876266 Train accuracy:0.9925690021231423 Validation loss:1.3140710592269897 Validation accuracy:0.811965811965812\n",
      "Epochs:263 Train loss:0.17699889512732625 Train accuracy:0.9925690021231423 Validation loss:1.450444221496582 Validation accuracy:0.8034188034188035\n",
      "Epochs:264 Train loss:0.15944894775748253 Train accuracy:0.9915074309978769 Validation loss:1.3166005611419678 Validation accuracy:0.7777777777777778\n",
      "Epochs:265 Train loss:0.21802216582000256 Train accuracy:0.9904458598726115 Validation loss:1.3829970359802246 Validation accuracy:0.8034188034188035\n",
      "Epochs:266 Train loss:0.1993887908756733 Train accuracy:0.9925690021231423 Validation loss:1.5367844104766846 Validation accuracy:0.8034188034188035\n",
      "Epochs:267 Train loss:0.19009127654135227 Train accuracy:0.9904458598726115 Validation loss:1.5140377283096313 Validation accuracy:0.811965811965812\n",
      "Epochs:268 Train loss:0.17282804427668452 Train accuracy:0.9925690021231423 Validation loss:1.3732589483261108 Validation accuracy:0.7863247863247863\n",
      "Epochs:269 Train loss:0.16751728067174554 Train accuracy:0.9925690021231423 Validation loss:1.409706950187683 Validation accuracy:0.7863247863247863\n",
      "Epochs:270 Train loss:0.16435289988294244 Train accuracy:0.9915074309978769 Validation loss:1.429716944694519 Validation accuracy:0.7863247863247863\n",
      "Epochs:271 Train loss:0.15723894722759724 Train accuracy:0.9925690021231423 Validation loss:1.366523265838623 Validation accuracy:0.7863247863247863\n",
      "Epochs:272 Train loss:0.14539908058941364 Train accuracy:0.9925690021231423 Validation loss:1.638674020767212 Validation accuracy:0.8034188034188035\n",
      "Epochs:273 Train loss:0.14197816886007786 Train accuracy:0.9925690021231423 Validation loss:1.540826678276062 Validation accuracy:0.7863247863247863\n",
      "Epochs:274 Train loss:0.13185612158849835 Train accuracy:0.9925690021231423 Validation loss:1.5261118412017822 Validation accuracy:0.7948717948717948\n",
      "Epochs:275 Train loss:0.16625312762334943 Train accuracy:0.9925690021231423 Validation loss:1.5078994035720825 Validation accuracy:0.7863247863247863\n",
      "Epochs:276 Train loss:0.16783289890736341 Train accuracy:0.9915074309978769 Validation loss:1.4614578485488892 Validation accuracy:0.7777777777777778\n",
      "Epochs:277 Train loss:0.15943922568112612 Train accuracy:0.9915074309978769 Validation loss:1.5802464485168457 Validation accuracy:0.7863247863247863\n",
      "Epochs:278 Train loss:0.12257554940879345 Train accuracy:0.9925690021231423 Validation loss:1.6345824003219604 Validation accuracy:0.7863247863247863\n",
      "Epochs:279 Train loss:0.12695883447304368 Train accuracy:0.9925690021231423 Validation loss:1.732587456703186 Validation accuracy:0.7948717948717948\n",
      "Epochs:280 Train loss:0.12387493485584855 Train accuracy:0.9925690021231423 Validation loss:1.6314047574996948 Validation accuracy:0.8034188034188035\n",
      "Epochs:281 Train loss:0.11362831061705947 Train accuracy:0.9925690021231423 Validation loss:1.7149920463562012 Validation accuracy:0.7948717948717948\n",
      "Epochs:282 Train loss:0.1077065197750926 Train accuracy:0.9925690021231423 Validation loss:1.5845495462417603 Validation accuracy:0.7777777777777778\n",
      "Epochs:283 Train loss:0.13346673548221588 Train accuracy:0.9915074309978769 Validation loss:1.49618399143219 Validation accuracy:0.7863247863247863\n",
      "Epochs:284 Train loss:0.1365544069558382 Train accuracy:0.9915074309978769 Validation loss:1.6552666425704956 Validation accuracy:0.7863247863247863\n",
      "Epochs:285 Train loss:0.14128485368564725 Train accuracy:0.9904458598726115 Validation loss:1.7368541955947876 Validation accuracy:0.7863247863247863\n",
      "Epochs:286 Train loss:0.11665163189172745 Train accuracy:0.9925690021231423 Validation loss:1.6162604093551636 Validation accuracy:0.7863247863247863\n",
      "Epochs:287 Train loss:0.129629444796592 Train accuracy:0.9925690021231423 Validation loss:1.6607582569122314 Validation accuracy:0.7692307692307693\n",
      "Epochs:288 Train loss:0.1151688601821661 Train accuracy:0.9925690021231423 Validation loss:1.7016210556030273 Validation accuracy:0.7948717948717948\n",
      "Epochs:289 Train loss:0.10066018253564835 Train accuracy:0.9925690021231423 Validation loss:1.6792412996292114 Validation accuracy:0.7692307692307693\n",
      "Epochs:290 Train loss:0.10529904928989708 Train accuracy:0.9925690021231423 Validation loss:1.7660483121871948 Validation accuracy:0.7948717948717948\n",
      "Epochs:291 Train loss:0.10337266558781266 Train accuracy:0.9925690021231423 Validation loss:1.6495648622512817 Validation accuracy:0.7777777777777778\n",
      "Epochs:292 Train loss:0.1202973099425435 Train accuracy:0.9915074309978769 Validation loss:1.687317967414856 Validation accuracy:0.7692307692307693\n",
      "Epochs:293 Train loss:0.0996141959913075 Train accuracy:0.9936305732484076 Validation loss:1.8241006135940552 Validation accuracy:0.7948717948717948\n",
      "Epochs:294 Train loss:0.08957870560698211 Train accuracy:0.9925690021231423 Validation loss:1.749032974243164 Validation accuracy:0.7948717948717948\n",
      "Epochs:295 Train loss:0.0921259147580713 Train accuracy:0.9936305732484076 Validation loss:1.7788270711898804 Validation accuracy:0.7948717948717948\n",
      "Epochs:296 Train loss:0.08004362031351775 Train accuracy:0.9936305732484076 Validation loss:1.738042950630188 Validation accuracy:0.7948717948717948\n",
      "Epochs:297 Train loss:0.08148682350292802 Train accuracy:0.9936305732484076 Validation loss:1.7300660610198975 Validation accuracy:0.7948717948717948\n",
      "Epochs:298 Train loss:0.09742277674376965 Train accuracy:0.9925690021231423 Validation loss:1.8551396131515503 Validation accuracy:0.7948717948717948\n",
      "Epochs:299 Train loss:0.08766851096879691 Train accuracy:0.9936305732484076 Validation loss:1.748552680015564 Validation accuracy:0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "do_training()"
   ]
  },
  {
   "source": [
    "### load best model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"saved_model_DD_SAGPool.pth\"\n",
    "model = Net(num_features,num_hidden,num_classes, pooling_ratio, dropout_ratio)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "283.01559376443504 0.7226890756302521\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc_epoch = val(test_loader)\n",
    "print(test_loss,test_acc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}