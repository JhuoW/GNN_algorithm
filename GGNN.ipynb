{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tensorflow2.x for [\"Gated Graph Sequence Neural Networks\"](https://arxiv.org/pdf/1511.05493.pdf)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "import pickle as pkl\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[1:2], device_type='GPU')"
   ]
  },
  {
   "source": [
    "## Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cora\"\n",
    "\n",
    "def preprocess_features(features):\n",
    "    row_sum = np.array(features.sum(1))\n",
    "    reverse_row_sum = np.power(row_sum,-1).flatten()\n",
    "    reverse_row_sum[np.isinf(reverse_row_sum)] = 0.\n",
    "    new_features = sp.diags(reverse_row_sum).dot(features)\n",
    "    return new_features\n",
    "\n",
    "def load_data(datasetname):\n",
    "    names = ['x','tx','allx','y','ty','ally','graph']\n",
    "    objects = {}\n",
    "    for name in names:\n",
    "        with open(\"data/ind.{}.{}\".format(datasetname, name),'rb') as f:\n",
    "            objects[name] = pkl.load(f, encoding='latin1')\n",
    "    \n",
    "    with open(\"data/ind.{}.test.index\".format(datasetname), 'r') as f:\n",
    "        test_index = []\n",
    "        for line in f.readlines():\n",
    "            test_index.append(int(line.strip()))\n",
    "\n",
    "    test_index_reorder = np.sort(test_index)\n",
    "    \n",
    "    whole_features = sp.vstack((objects['allx'], objects['tx'])).tolil()\n",
    "\n",
    "    whole_features[test_index] = whole_features[test_index_reorder]\n",
    "\n",
    "    num_nodes = whole_features.shape[0]\n",
    "\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(objects['graph']))\n",
    "\n",
    "    whole_labels = np.r_[objects['ally'], objects['ty']]\n",
    "\n",
    "    whole_labels[test_index] = whole_labels[test_index_reorder]\n",
    "\n",
    "    train_idx = np.arange(len(objects['y']))\n",
    "    val_idx = np.arange(len(objects['y']), len(objects['y'])+ 500)\n",
    "    test_idx = test_index_reorder\n",
    "\n",
    "\n",
    "\n",
    "    return adj, whole_features, whole_labels, train_idx, val_idx, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, whole_features, whole_labels, train_idx, val_idx, test_idx = load_data(dataset_name)\n",
    "wholes_features = preprocess_features(whole_features).todense()"
   ]
  },
  {
   "source": [
    "## Build Graph"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"302.4pt\" version=\"1.1\" viewBox=\"0 0 446.4 302.4\" width=\"446.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 302.4 \nL 446.4 302.4 \nL 446.4 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"LineCollection_1\">\n    <path clip-path=\"url(#pe466ef11b8)\" d=\"M 412.558294 79.568343 \nL 414.536271 200.641667 \n\" style=\"fill:none;stroke:#000000;stroke-opacity:0.9;\"/>\n    <path clip-path=\"url(#pe466ef11b8)\" d=\"M 412.558294 79.568343 \nL 296.495128 143.584182 \n\" style=\"fill:none;stroke:#000000;stroke-opacity:0.9;\"/>\n    <path clip-path=\"url(#pe466ef11b8)\" d=\"M 414.536271 200.641667 \nL 296.495128 143.584182 \n\" style=\"fill:none;stroke:#000000;stroke-opacity:0.9;\"/>\n    <path clip-path=\"url(#pe466ef11b8)\" d=\"M 296.495128 143.584182 \nL 130.615169 148.468691 \n\" style=\"fill:none;stroke:#000000;stroke-opacity:0.9;\"/>\n    <path clip-path=\"url(#pe466ef11b8)\" d=\"M 130.615169 148.468691 \nL 35.627033 272.116123 \n\" style=\"fill:none;stroke:#000000;stroke-opacity:0.9;\"/>\n    <path clip-path=\"url(#pe466ef11b8)\" d=\"M 130.615169 148.468691 \nL 31.863729 30.283877 \n\" style=\"fill:none;stroke:#000000;stroke-opacity:0.9;\"/>\n   </g>\n   <g id=\"text_1\">\n    <g id=\"patch_2\">\n     <path clip-path=\"url(#pe466ef11b8)\" d=\"M 405.6573 137.052229 \nL 405.761231 143.41388 \nQ 405.810235 146.41348 408.809835 146.364475 \nL 418.486669 146.206385 \nQ 421.486268 146.15738 421.437264 143.15778 \nL 421.333334 136.796129 \nQ 421.284329 133.79653 418.284729 133.845534 \nL 408.607896 134.003625 \nQ 405.608296 134.052629 405.6573 137.052229 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;\"/>\n    </g>\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 0 -->\n     <defs>\n      <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n     </defs>\n     <g style=\"fill:#ff0000;\" transform=\"translate(410.73631 136.969253)rotate(-270.935959)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_2\">\n    <g id=\"patch_3\">\n     <path clip-path=\"url(#pe466ef11b8)\" d=\"M 349.239984 177.786252 \nL 354.968373 180.55518 \nQ 357.669382 181.860765 358.974967 179.159757 \nL 363.186839 170.44619 \nQ 364.492424 167.745182 361.791415 166.439597 \nL 356.063026 163.670668 \nQ 353.362017 162.365083 352.056432 165.066092 \nL 347.84456 173.779658 \nQ 346.538975 176.480667 349.239984 177.786252 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;\"/>\n    </g>\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 1 -->\n     <defs>\n      <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n     </defs>\n     <g style=\"fill:#ff0000;\" transform=\"translate(351.450639 173.212825)rotate(-334.202295)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <g id=\"patch_4\">\n     <path clip-path=\"url(#pe466ef11b8)\" d=\"M 210.606006 153.955737 \nL 216.96575 153.768468 \nQ 219.96445 153.680168 219.87615 150.681468 \nL 219.591291 141.007536 \nQ 219.502991 138.008836 216.504291 138.097135 \nL 210.144548 138.284405 \nQ 207.145847 138.372705 207.234147 141.371405 \nL 207.519006 151.045337 \nQ 207.607306 154.044037 210.606006 153.955737 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;\"/>\n    </g>\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 2 -->\n     <defs>\n      <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n     </defs>\n     <g style=\"fill:#ff0000;\" transform=\"translate(210.456494 148.87825)rotate(-1.686647)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_4\">\n    <g id=\"patch_5\">\n     <path clip-path=\"url(#pe466ef11b8)\" d=\"M 87.399536 217.590779 \nL 91.275608 212.54524 \nQ 93.103226 210.166204 90.72419 208.338586 \nL 83.049319 202.442615 \nQ 80.670283 200.614998 78.842665 202.994034 \nL 74.966593 208.039574 \nQ 73.138975 210.41861 75.518012 212.246227 \nL 83.192882 218.142198 \nQ 85.571918 219.969816 87.399536 217.590779 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;\"/>\n    </g>\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 0 -->\n     <g style=\"fill:#ff0000;\" transform=\"translate(83.371282 214.496204)rotate(-52.467895)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_5\">\n    <g id=\"patch_6\">\n     <path clip-path=\"url(#pe466ef11b8)\" d=\"M 355.527098 119.976886 \nL 361.098347 116.904006 \nQ 363.725262 115.455104 362.27636 112.828189 \nL 357.602141 104.353652 \nQ 356.153239 101.726737 353.526324 103.175639 \nL 347.955075 106.248519 \nQ 345.32816 107.697421 346.777062 110.324336 \nL 351.451281 118.798873 \nQ 352.900183 121.425788 355.527098 119.976886 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;\"/>\n    </g>\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 1 -->\n     <g style=\"fill:#ff0000;\" transform=\"translate(353.073775 115.528917)rotate(-28.879386)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_6\">\n    <g id=\"patch_7\">\n     <path clip-path=\"url(#pe466ef11b8)\" d=\"M 73.184126 91.961439 \nL 77.263735 96.843877 \nQ 79.187322 99.146009 81.489454 97.222422 \nL 88.916228 91.016848 \nQ 91.218359 89.093261 89.294772 86.791129 \nL 85.215163 81.908691 \nQ 83.291576 79.606559 80.989444 81.530147 \nL 73.562671 87.73572 \nQ 71.260539 89.659308 73.184126 91.961439 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;\"/>\n    </g>\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 2 -->\n     <g style=\"fill:#ff0000;\" transform=\"translate(77.082163 88.704365)rotate(-309.881048)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 11.18034 \nC 2.965061 11.18034 5.80908 10.002309 7.905694 7.905694 \nC 10.002309 5.80908 11.18034 2.965061 11.18034 0 \nC 11.18034 -2.965061 10.002309 -5.80908 7.905694 -7.905694 \nC 5.80908 -10.002309 2.965061 -11.18034 0 -11.18034 \nC -2.965061 -11.18034 -5.80908 -10.002309 -7.905694 -7.905694 \nC -10.002309 -5.80908 -11.18034 -2.965061 -11.18034 0 \nC -11.18034 2.965061 -10.002309 5.80908 -7.905694 7.905694 \nC -5.80908 10.002309 -2.965061 11.18034 0 11.18034 \nz\n\" id=\"m2795411416\" style=\"stroke:#ffc0cb;stroke-opacity:0.9;\"/>\n    </defs>\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <use style=\"fill:#ffc0cb;fill-opacity:0.9;stroke:#ffc0cb;stroke-opacity:0.9;\" x=\"412.558294\" xlink:href=\"#m2795411416\" y=\"79.568343\"/>\n     <use style=\"fill:#ffc0cb;fill-opacity:0.9;stroke:#ffc0cb;stroke-opacity:0.9;\" x=\"414.536271\" xlink:href=\"#m2795411416\" y=\"200.641667\"/>\n     <use style=\"fill:#ffc0cb;fill-opacity:0.9;stroke:#ffc0cb;stroke-opacity:0.9;\" x=\"296.495128\" xlink:href=\"#m2795411416\" y=\"143.584182\"/>\n     <use style=\"fill:#ffc0cb;fill-opacity:0.9;stroke:#ffc0cb;stroke-opacity:0.9;\" x=\"130.615169\" xlink:href=\"#m2795411416\" y=\"148.468691\"/>\n     <use style=\"fill:#ffc0cb;fill-opacity:0.9;stroke:#ffc0cb;stroke-opacity:0.9;\" x=\"35.627033\" xlink:href=\"#m2795411416\" y=\"272.116123\"/>\n     <use style=\"fill:#ffc0cb;fill-opacity:0.9;stroke:#ffc0cb;stroke-opacity:0.9;\" x=\"31.863729\" xlink:href=\"#m2795411416\" y=\"30.283877\"/>\n    </g>\n   </g>\n   <g id=\"text_7\">\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 0 -->\n     <g style=\"opacity:0.9;\" transform=\"translate(408.740794 82.879593)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_8\">\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 1 -->\n     <g style=\"opacity:0.9;\" transform=\"translate(410.718771 203.952917)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_9\">\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 2 -->\n     <g style=\"opacity:0.9;\" transform=\"translate(292.677628 146.895432)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_10\">\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 3 -->\n     <defs>\n      <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n     </defs>\n     <g style=\"opacity:0.9;\" transform=\"translate(126.797669 151.779941)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-51\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_11\">\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 4 -->\n     <defs>\n      <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n     </defs>\n     <g style=\"opacity:0.9;\" transform=\"translate(31.809533 275.427373)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-52\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_12\">\n    <g clip-path=\"url(#pe466ef11b8)\">\n     <!-- 5 -->\n     <defs>\n      <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n     </defs>\n     <g style=\"opacity:0.9;\" transform=\"translate(28.046229 33.595127)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe466ef11b8\">\n   <rect height=\"288\" width=\"432\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "def build_graph(edges, edgetypes):    \n",
    "    g = nx.Graph()\n",
    "\n",
    "    for i, edge in enumerate(edges):\n",
    "        g.add_edge(edge[0],edge[1],label = edgetypes[i])\n",
    "\n",
    "    pos = nx.spring_layout(g)\n",
    "    plt.figure()\n",
    "    nx.draw(g,\n",
    "            pos,\n",
    "            edge_color='black',\n",
    "            width=1,\n",
    "            linewidths=1,\n",
    "            node_size=500,\n",
    "            node_color='pink',\n",
    "            alpha=0.9,\n",
    "            labels={node:node for node in g.nodes()})\n",
    "\n",
    "    nx.draw_networkx_edge_labels(g,\n",
    "                                 pos,\n",
    "                                 edge_labels={(edges[0][0],edges[0][1]):edgetypes[0],\n",
    "                                              (edges[1][0],edges[1][1]):edgetypes[1],\n",
    "                                              (edges[2][0],edges[2][1]):edgetypes[2],\n",
    "                                              (edges[3][0],edges[3][1]):edgetypes[3],\n",
    "                                              (edges[4][0],edges[4][1]):edgetypes[4],\n",
    "                                              (edges[5][0],edges[5][1]):edgetypes[5]},font_color='red')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return g\n",
    "\n",
    "\n",
    "\n",
    "edges = np.array([[0,1,2,3,2,5], [1,2,3,4,0,3]]).T\n",
    "sorted_edges = np.sort(edges)\n",
    "features = np.ones(shape = (6, 10))\n",
    "edgetypes = np.array([0,1,2,0,1,2])\n",
    "g = build_graph(edges, edgetypes)\n",
    "feature_dims = features.shape[1]\n",
    "output_dims = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(g) # without self loop\n"
   ]
  },
  {
   "source": [
    "## Model\n",
    "\n",
    "$h_{i}^{0} = [ x_i \\| \\mathbf{0} ]$\n",
    "\n",
    "$a_{i}^{t} = \\sum_{j\\in\\mathcal{N}(i)} W_{e_{ij}} h_{j}^{t}$\n",
    "\n",
    "$h_{i}^{t+1} = \\mathrm{GRU}(a_{i}^{t}, h_{i}^{t})$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_nodes = features.shape[0]\n",
    "# feature_dim = features.shape[1]\n",
    "# epochs = 500\n",
    "# n_classes = whole_labels.shape[1]\n",
    "# learning_rate = 5e-3\n",
    "# L2_reg = 5e-4\n",
    "\n",
    "class GatedGNN(keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 output_dims, \n",
    "                 g, \n",
    "                 class_num = None,\n",
    "                 activation = keras.activations.softmax,\n",
    "                 sparse = True,\n",
    "                 n_steps=2, \n",
    "                 n_edgeTypes = 3, \n",
    "                 bias = True, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        feature_dims: input features size,\n",
    "        output_dims: output node_size,\n",
    "        direct: bool,\n",
    "        n_steps: num of steps of GRU (T in paper),\n",
    "        n_edgetypes: num of edgeTypes,\n",
    "        bias: default true.\n",
    "\n",
    "         The number of input channels of :math:`\\mathbf{x}_i` needs to be less or\n",
    "    equal than :obj:`out_channels`.\n",
    "        \"\"\"\n",
    "        super(GatedGNN, self).__init__(**kwargs)\n",
    "        self.output_dims = output_dims\n",
    "        self.n_steps = n_steps\n",
    "        self.n_edgeTypes = n_edgeTypes\n",
    "        self.bias = bias\n",
    "        self.sparse = sparse\n",
    "        self.gru = keras.layers.GRUCell(units = self.output_dims, use_bias=self.bias)\n",
    "        self.g = g\n",
    "        self.class_num = class_num\n",
    "        # 为解决over fitting 先做个特征变换\n",
    "        self.solve_overfitting = keras.layers.Dense(self.output_dims)\n",
    "\n",
    "        # 每种类型的边赋予不同的weight 每个节点聚合outgoing neigh和incoming neigh\n",
    "        self.edge_weights =[\n",
    "            keras.layers.Dense(units = self.output_dims, \n",
    "                               kernel_initializer = keras.initializers.GlorotUniform, \n",
    "                               bias_initializer = keras.initializers.zeros,\n",
    "                               use_bias=self.bias) \n",
    "            for _ in range(self.n_edgeTypes)\n",
    "        ]\n",
    "        if self.class_num is not None:\n",
    "            self.output_layer = keras.layers.Dense(self.class_num)\n",
    "        self.activation = activation\n",
    "        self.num_nodes = self.g.number_of_nodes()\n",
    "        self.adj_matrix = nx.adjacency_matrix(self.g)\n",
    "        if self.n_edgeTypes > 1:\n",
    "            self._process_graph()\n",
    "        \n",
    "    \n",
    "    def _process_graph(self):\n",
    "        \"\"\" \n",
    "        label: edges\n",
    "        {   0: [(0, 1), (1, 0), (3, 4), (4, 3)],\n",
    "            1: [(0, 2), (1, 2), (2, 1), (2, 0)],\n",
    "            2: [(2, 3), (3, 2), (3, 5), (5, 3)] }\n",
    "        \"\"\"\n",
    "        self.adj = self.g.adj\n",
    "        self.label_edge_dict = {}\n",
    "        for item in self.adj.items():\n",
    "            head = item[0]\n",
    "            tails = item[1]\n",
    "            for node in tails.items():\n",
    "                tail = node[0]\n",
    "                label = node[1]['label']\n",
    "                if label not in self.label_edge_dict:\n",
    "                    self.label_edge_dict[label] = []\n",
    "                self.label_edge_dict[label].append((head, tail))\n",
    "    \n",
    "    def _get_edgedict(self, label):\n",
    "        edge_dict = {}\n",
    "        if self.n_edgeTypes > 1:\n",
    "            edges = self.label_edge_dict[label]\n",
    "            for edge in edges:\n",
    "                head = edge[0]\n",
    "                tail = edge[1]\n",
    "                if head not in edge_dict:\n",
    "                    edge_dict[head] = set()\n",
    "                if tail not in edge_dict:\n",
    "                    edge_dict[tail] = set()\n",
    "                edge_dict[head].add(tail)\n",
    "                edge_dict[tail].add(head)\n",
    "        else:\n",
    "            edges = list(self.g.edges)\n",
    "            for edge in edges:\n",
    "                head = edge[0]\n",
    "                tail = edge[1]\n",
    "                if head not in edge_dict:\n",
    "                    edge_dict[head] = set()\n",
    "                if tail not in edge_dict:\n",
    "                    edge_dict[tail] = set()\n",
    "                edge_dict[head].add(tail)\n",
    "                edge_dict[tail].add(head)\n",
    "        return edge_dict\n",
    "\n",
    "    def _message_passing(self, features, adj_mask):\n",
    "        adj_mask = self._csr_to_SparseTensor(adj_mask)\n",
    "        agg = tf.sparse.sparse_dense_matmul(tf.cast(adj_mask,tf.float32), features) # neigh aggregation\n",
    "        return agg\n",
    "\n",
    "    def _dense_to_csr(self, edges):\n",
    "        num_data = edges.shape[1]\n",
    "        edges = edges.T\n",
    "        row = edges[0]\n",
    "        col = edges[1]\n",
    "        data  = np.arange(edges.shape[1])\n",
    "        return sp.csr_matrix((data,(row,col)),shape = (self.num_nodes, self.num_nodes))\n",
    "\n",
    "    def _csr_to_SparseTensor(self, csr_matrix):\n",
    "        if sp.isspmatrix_csr(csr_matrix):\n",
    "            csr_matrix = csr_matrix.tocoo()\n",
    "        row = csr_matrix.row\n",
    "        col = csr_matrix.col\n",
    "        pos = np.c_[row,col]\n",
    "        data = csr_matrix.data\n",
    "        shape = csr_matrix.shape\n",
    "        return tf.SparseTensor(pos, data, shape)\n",
    "\n",
    "\n",
    "    def _mask_adj(self, edge_type):\n",
    "        # edge_type = 0,1,2\n",
    "        if self.n_edgeTypes > 1:\n",
    "            edges = self.label_edge_dict[edge_type]\n",
    "            edges = np.array(list(map(lambda x: list(x), edges)))\n",
    "            if not self.sparse:\n",
    "                mask_adj = np.zeros(shape=(self.num_nodes,self.num_nodes),dtype = np.int)\n",
    "                mask_adj[edges[:,0], edges[:,1]] = 1\n",
    "                return mask_adj\n",
    "            else:\n",
    "                mask_adj = self._dense_to_csr(edges)\n",
    "                return mask_adj\n",
    "        else:\n",
    "            edges = self.g.edges\n",
    "            edges = np.array(list(map(lambda x: list(x), edges)))\n",
    "            if not self.sparse:\n",
    "                mask_adj = np.zeros(shape=(self.num_nodes,self.num_nodes),dtype = np.int)\n",
    "                mask_adj[edges[:,0], edges[:,1]] = 1\n",
    "                return mask_adj\n",
    "            else:\n",
    "                mask_adj = self._dense_to_csr(edges)\n",
    "                return mask_adj\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        features = inputs\n",
    "        if self.output_dims > features.shape[1]:\n",
    "            # zero_pad = tf.zeros(shape = (features.shape[0], int(self.output_dims - features.shape[1])))\n",
    "            # features = tf.concat([features, zero_pad], axis = 1)\n",
    "            zero_pad = int(self.output_dims - features.shape[1])\n",
    "            padding = [[0,0],[0,zero_pad]]\n",
    "            features = tf.pad(features,padding,\"CONSTANT\")\n",
    "        features = self.solve_overfitting(features)\n",
    "        for _ in range(self.n_steps):\n",
    "            agg_whole = []\n",
    "            for i in range(self.n_edgeTypes):\n",
    "                # edges = self.label_edge_dict[i]\n",
    "                # edge_dict = self._get_edgedict(i)\n",
    "                # head = list(edge_dict.keys())\n",
    "                # neighbor_of_head = np.array(list(\n",
    "                #     map(lambda x: list(x), list(edge_dict.values()))))\n",
    "\n",
    "                # message passing\n",
    "                Wh_j = self.edge_weights[i](features)  # feature transform\n",
    "                # 只包含edgeType[i]的邻接矩阵\n",
    "                edgeType_adj_mask = self._mask_adj(i)\n",
    "                # 为每个节点聚合edge type = i的邻居特征\n",
    "                agg = self._message_passing(Wh_j, edgeType_adj_mask) # NxD\n",
    "                agg_whole.append(agg)\n",
    "            a = tf.reduce_sum(tf.stack(agg_whole, axis=0), axis=0)\n",
    "            features = self.gru(a, features)[0]\n",
    "        if self.class_num is not None:\n",
    "            out = self.output_layer(features)\n",
    "            features = self.activation(out)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 10)]              0         \n_________________________________________________________________\ngated_gnn (GatedGNN)         (6, 11)                   1221      \n=================================================================\nTotal params: 1,221\nTrainable params: 1,221\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(feature_dims,))\n",
    "\n",
    "gategnn = GatedGNN(output_dims=11,\n",
    "                   g = g,\n",
    "                   n_steps=2,\n",
    "                   n_edgeTypes=3,\n",
    "                   bias=False)(inputs)\n",
    "\n",
    "model = keras.models.Model(inputs = inputs, outputs = gategnn)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 11), dtype=float32, numpy=\n",
       "array([[-0.19561294, -0.18606089, -0.3058448 , -0.00210386, -0.22446665,\n",
       "         0.06467547,  0.21159919, -0.5133848 , -0.24325022, -0.05635349,\n",
       "         0.24905029],\n",
       "       [-0.8035495 , -0.5949438 , -0.9550313 , -0.04554544, -0.29970688,\n",
       "        -0.38233182,  0.0114895 ,  0.02880734, -0.850068  ,  0.45329002,\n",
       "         0.6557997 ],\n",
       "       [-0.9402922 , -0.22307855,  0.6025761 , -0.46428153, -0.7155764 ,\n",
       "        -0.9656445 , -0.6957068 ,  0.8176597 , -0.8994152 ,  0.77796894,\n",
       "         0.7788987 ],\n",
       "       [-0.8356583 , -1.0829695 , -1.1067482 ,  0.00159816, -0.41905516,\n",
       "         0.26678243,  0.62082684, -0.80135363, -0.70830625,  0.18730104,\n",
       "        -0.02687861],\n",
       "       [-0.9959234 , -0.57641053, -1.3924615 ,  0.06712859, -0.6346684 ,\n",
       "        -0.55409473,  0.9210373 , -0.6864879 , -0.8501884 ,  0.95742124,\n",
       "         0.510429  ],\n",
       "       [-0.41796333, -1.3016931 , -0.32993513, -0.02813825, -0.40931883,\n",
       "         0.729366  ,  0.9909551 , -0.7588412 ,  0.88559264, -0.35233593,\n",
       "        -0.33488807]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model(features)"
   ]
  },
  {
   "source": [
    "# Train on Cora for Node Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cora = nx.from_scipy_sparse_matrix(adj)  # return nx Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_dims = whole_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 1433)]            0         \n_________________________________________________________________\ngated_gnn_1 (GatedGNN)       (2708, 7)                 24855     \n=================================================================\nTotal params: 24,855\nTrainable params: 24,855\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_nodes = whole_features.shape[0]\n",
    "feature_dim = whole_features.shape[1]\n",
    "epochs = 500\n",
    "n_classes = whole_labels.shape[1]\n",
    "learning_rate = 5e-3\n",
    "L2_reg = 5e-4\n",
    "\n",
    "embed_dims = 16\n",
    "inputs = keras.Input(shape=(cora_dims,))\n",
    "\n",
    "gated_cora = GatedGNN(output_dims=embed_dims,\n",
    "                   g = G_cora,\n",
    "                   class_num = n_classes,\n",
    "                   n_steps=1,\n",
    "                   n_edgeTypes=1,\n",
    "                   bias=False)(inputs)\n",
    "\n",
    "model_cora = keras.models.Model(inputs = inputs, outputs = gated_cora )\n",
    "model_cora.summary()\n",
    "\n",
    "model_cora.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(learning_rate),\n",
    "weighted_metrics=['categorical_crossentropy', 'acc'])"
   ]
  },
  {
   "source": [
    "## Generate Train Valid Test Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mask(idx, l):\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "y_train = np.zeros(whole_labels.shape)\n",
    "train_mask = sample_mask(train_idx, whole_labels.shape[0])\n",
    "y_train[train_mask] = whole_labels[train_mask]\n",
    "\n",
    "y_val = np.zeros(whole_labels.shape)\n",
    "val_mask = sample_mask(val_idx, whole_labels.shape[0])\n",
    "y_val[val_mask] = whole_labels[val_mask]\n",
    "\n",
    "y_test = np.zeros(whole_labels.shape)\n",
    "test_mask = sample_mask(test_idx, whole_labels.shape[0])\n",
    "y_test[test_mask] = whole_labels[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ategorical_crossentropy: 1.8873 - val_acc: 0.5000\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9001e-04 - categorical_crossentropy: 0.0075 - acc: 1.0000 - val_loss: 0.3487 - val_categorical_crossentropy: 1.8884 - val_acc: 0.5000\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.8783e-04 - categorical_crossentropy: 0.0075 - acc: 1.0000 - val_loss: 0.3488 - val_categorical_crossentropy: 1.8894 - val_acc: 0.5000\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.8566e-04 - categorical_crossentropy: 0.0075 - acc: 1.0000 - val_loss: 0.3490 - val_categorical_crossentropy: 1.8902 - val_acc: 0.4980\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.8351e-04 - categorical_crossentropy: 0.0074 - acc: 1.0000 - val_loss: 0.3491 - val_categorical_crossentropy: 1.8910 - val_acc: 0.4980\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.8138e-04 - categorical_crossentropy: 0.0074 - acc: 1.0000 - val_loss: 0.3493 - val_categorical_crossentropy: 1.8917 - val_acc: 0.4980\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.7927e-04 - categorical_crossentropy: 0.0073 - acc: 1.0000 - val_loss: 0.3494 - val_categorical_crossentropy: 1.8922 - val_acc: 0.4980\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7717e-04 - categorical_crossentropy: 0.0073 - acc: 1.0000 - val_loss: 0.3495 - val_categorical_crossentropy: 1.8927 - val_acc: 0.4980\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7504e-04 - categorical_crossentropy: 0.0073 - acc: 1.0000 - val_loss: 0.3495 - val_categorical_crossentropy: 1.8931 - val_acc: 0.4980\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7223e-04 - categorical_crossentropy: 0.0072 - acc: 1.0000 - val_loss: 0.3496 - val_categorical_crossentropy: 1.8935 - val_acc: 0.4980\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.7010e-04 - categorical_crossentropy: 0.0072 - acc: 1.0000 - val_loss: 0.3497 - val_categorical_crossentropy: 1.8941 - val_acc: 0.4980\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.6808e-04 - categorical_crossentropy: 0.0071 - acc: 1.0000 - val_loss: 0.3498 - val_categorical_crossentropy: 1.8948 - val_acc: 0.4980\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.6608e-04 - categorical_crossentropy: 0.0071 - acc: 1.0000 - val_loss: 0.3499 - val_categorical_crossentropy: 1.8951 - val_acc: 0.4980\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6408e-04 - categorical_crossentropy: 0.0070 - acc: 1.0000 - val_loss: 0.3499 - val_categorical_crossentropy: 1.8951 - val_acc: 0.4980\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6208e-04 - categorical_crossentropy: 0.0070 - acc: 1.0000 - val_loss: 0.3499 - val_categorical_crossentropy: 1.8949 - val_acc: 0.5000\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.5999e-04 - categorical_crossentropy: 0.0070 - acc: 1.0000 - val_loss: 0.3498 - val_categorical_crossentropy: 1.8946 - val_acc: 0.5000\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5734e-04 - categorical_crossentropy: 0.0069 - acc: 1.0000 - val_loss: 0.3498 - val_categorical_crossentropy: 1.8945 - val_acc: 0.5000\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5853e-04 - categorical_crossentropy: 0.0069 - acc: 1.0000 - val_loss: 0.3499 - val_categorical_crossentropy: 1.8951 - val_acc: 0.5000\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.5332e-04 - categorical_crossentropy: 0.0068 - acc: 1.0000 - val_loss: 0.3502 - val_categorical_crossentropy: 1.8965 - val_acc: 0.5000\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.5260e-04 - categorical_crossentropy: 0.0068 - acc: 1.0000 - val_loss: 0.3505 - val_categorical_crossentropy: 1.8984 - val_acc: 0.5000\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.5079e-04 - categorical_crossentropy: 0.0068 - acc: 1.0000 - val_loss: 0.3507 - val_categorical_crossentropy: 1.8995 - val_acc: 0.5000\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4895e-04 - categorical_crossentropy: 0.0067 - acc: 1.0000 - val_loss: 0.3508 - val_categorical_crossentropy: 1.9000 - val_acc: 0.5000\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.4712e-04 - categorical_crossentropy: 0.0067 - acc: 1.0000 - val_loss: 0.3508 - val_categorical_crossentropy: 1.8998 - val_acc: 0.5020\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.4531e-04 - categorical_crossentropy: 0.0067 - acc: 1.0000 - val_loss: 0.3507 - val_categorical_crossentropy: 1.8992 - val_acc: 0.5020\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4351e-04 - categorical_crossentropy: 0.0066 - acc: 1.0000 - val_loss: 0.3506 - val_categorical_crossentropy: 1.8991 - val_acc: 0.5020\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4173e-04 - categorical_crossentropy: 0.0066 - acc: 1.0000 - val_loss: 0.3507 - val_categorical_crossentropy: 1.8994 - val_acc: 0.5020\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3996e-04 - categorical_crossentropy: 0.0066 - acc: 1.0000 - val_loss: 0.3508 - val_categorical_crossentropy: 1.8999 - val_acc: 0.5020\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3818e-04 - categorical_crossentropy: 0.0065 - acc: 1.0000 - val_loss: 0.3509 - val_categorical_crossentropy: 1.9006 - val_acc: 0.5020\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3622e-04 - categorical_crossentropy: 0.0065 - acc: 1.0000 - val_loss: 0.3511 - val_categorical_crossentropy: 1.9018 - val_acc: 0.5020\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.2660e-04 - categorical_crossentropy: 0.0063 - acc: 1.0000 - val_loss: 0.3514 - val_categorical_crossentropy: 1.9032 - val_acc: 0.5020\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2482e-04 - categorical_crossentropy: 0.0063 - acc: 1.0000 - val_loss: 0.3517 - val_categorical_crossentropy: 1.9046 - val_acc: 0.5020\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.2318e-04 - categorical_crossentropy: 0.0063 - acc: 1.0000 - val_loss: 0.3519 - val_categorical_crossentropy: 1.9060 - val_acc: 0.5020\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2153e-04 - categorical_crossentropy: 0.0062 - acc: 1.0000 - val_loss: 0.3521 - val_categorical_crossentropy: 1.9072 - val_acc: 0.5020\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1988e-04 - categorical_crossentropy: 0.0062 - acc: 1.0000 - val_loss: 0.3523 - val_categorical_crossentropy: 1.9083 - val_acc: 0.5020\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.1827e-04 - categorical_crossentropy: 0.0062 - acc: 1.0000 - val_loss: 0.3525 - val_categorical_crossentropy: 1.9093 - val_acc: 0.5020\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.1667e-04 - categorical_crossentropy: 0.0061 - acc: 1.0000 - val_loss: 0.3527 - val_categorical_crossentropy: 1.9103 - val_acc: 0.5000\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1508e-04 - categorical_crossentropy: 0.0061 - acc: 1.0000 - val_loss: 0.3529 - val_categorical_crossentropy: 1.9112 - val_acc: 0.5000\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.1351e-04 - categorical_crossentropy: 0.0061 - acc: 1.0000 - val_loss: 0.3530 - val_categorical_crossentropy: 1.9121 - val_acc: 0.5000\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1195e-04 - categorical_crossentropy: 0.0060 - acc: 1.0000 - val_loss: 0.3533 - val_categorical_crossentropy: 1.9134 - val_acc: 0.5000\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1040e-04 - categorical_crossentropy: 0.0060 - acc: 1.0000 - val_loss: 0.3534 - val_categorical_crossentropy: 1.9143 - val_acc: 0.5000\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0887e-04 - categorical_crossentropy: 0.0060 - acc: 1.0000 - val_loss: 0.3536 - val_categorical_crossentropy: 1.9151 - val_acc: 0.5000\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0735e-04 - categorical_crossentropy: 0.0059 - acc: 1.0000 - val_loss: 0.3537 - val_categorical_crossentropy: 1.9157 - val_acc: 0.5000\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0585e-04 - categorical_crossentropy: 0.0059 - acc: 1.0000 - val_loss: 0.3537 - val_categorical_crossentropy: 1.9157 - val_acc: 0.5000\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0435e-04 - categorical_crossentropy: 0.0059 - acc: 1.0000 - val_loss: 0.3536 - val_categorical_crossentropy: 1.9151 - val_acc: 0.5000\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0287e-04 - categorical_crossentropy: 0.0059 - acc: 1.0000 - val_loss: 0.3536 - val_categorical_crossentropy: 1.9150 - val_acc: 0.5000\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0140e-04 - categorical_crossentropy: 0.0058 - acc: 1.0000 - val_loss: 0.3537 - val_categorical_crossentropy: 1.9155 - val_acc: 0.5000\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.9994e-04 - categorical_crossentropy: 0.0058 - acc: 1.0000 - val_loss: 0.3538 - val_categorical_crossentropy: 1.9162 - val_acc: 0.5000\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.9849e-04 - categorical_crossentropy: 0.0058 - acc: 1.0000 - val_loss: 0.3539 - val_categorical_crossentropy: 1.9169 - val_acc: 0.4980\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9706e-04 - categorical_crossentropy: 0.0057 - acc: 1.0000 - val_loss: 0.3541 - val_categorical_crossentropy: 1.9176 - val_acc: 0.4980\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.9563e-04 - categorical_crossentropy: 0.0057 - acc: 1.0000 - val_loss: 0.3542 - val_categorical_crossentropy: 1.9184 - val_acc: 0.4980\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.9422e-04 - categorical_crossentropy: 0.0057 - acc: 1.0000 - val_loss: 0.3543 - val_categorical_crossentropy: 1.9191 - val_acc: 0.4980\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.9282e-04 - categorical_crossentropy: 0.0057 - acc: 1.0000 - val_loss: 0.3545 - val_categorical_crossentropy: 1.9198 - val_acc: 0.4980\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.9143e-04 - categorical_crossentropy: 0.0056 - acc: 1.0000 - val_loss: 0.3546 - val_categorical_crossentropy: 1.9205 - val_acc: 0.4980\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9005e-04 - categorical_crossentropy: 0.0056 - acc: 1.0000 - val_loss: 0.3547 - val_categorical_crossentropy: 1.9212 - val_acc: 0.4980\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.8868e-04 - categorical_crossentropy: 0.0056 - acc: 1.0000 - val_loss: 0.3548 - val_categorical_crossentropy: 1.9218 - val_acc: 0.4980\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.8732e-04 - categorical_crossentropy: 0.0056 - acc: 1.0000 - val_loss: 0.3550 - val_categorical_crossentropy: 1.9225 - val_acc: 0.4980\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.8597e-04 - categorical_crossentropy: 0.0055 - acc: 1.0000 - val_loss: 0.3551 - val_categorical_crossentropy: 1.9232 - val_acc: 0.4980\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.8463e-04 - categorical_crossentropy: 0.0055 - acc: 1.0000 - val_loss: 0.3552 - val_categorical_crossentropy: 1.9239 - val_acc: 0.4980\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.8330e-04 - categorical_crossentropy: 0.0055 - acc: 1.0000 - val_loss: 0.3554 - val_categorical_crossentropy: 1.9246 - val_acc: 0.4980\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8198e-04 - categorical_crossentropy: 0.0055 - acc: 1.0000 - val_loss: 0.3555 - val_categorical_crossentropy: 1.9253 - val_acc: 0.4980\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8067e-04 - categorical_crossentropy: 0.0054 - acc: 1.0000 - val_loss: 0.3556 - val_categorical_crossentropy: 1.9261 - val_acc: 0.4980\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.7936e-04 - categorical_crossentropy: 0.0054 - acc: 1.0000 - val_loss: 0.3558 - val_categorical_crossentropy: 1.9270 - val_acc: 0.4980\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7807e-04 - categorical_crossentropy: 0.0054 - acc: 1.0000 - val_loss: 0.3560 - val_categorical_crossentropy: 1.9280 - val_acc: 0.4980\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.7678e-04 - categorical_crossentropy: 0.0054 - acc: 1.0000 - val_loss: 0.3562 - val_categorical_crossentropy: 1.9292 - val_acc: 0.4980\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.7551e-04 - categorical_crossentropy: 0.0053 - acc: 1.0000 - val_loss: 0.3564 - val_categorical_crossentropy: 1.9303 - val_acc: 0.4980\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.7423e-04 - categorical_crossentropy: 0.0053 - acc: 1.0000 - val_loss: 0.3566 - val_categorical_crossentropy: 1.9313 - val_acc: 0.4980\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.7297e-04 - categorical_crossentropy: 0.0053 - acc: 1.0000 - val_loss: 0.3568 - val_categorical_crossentropy: 1.9322 - val_acc: 0.4980\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.7170e-04 - categorical_crossentropy: 0.0053 - acc: 1.0000 - val_loss: 0.3569 - val_categorical_crossentropy: 1.9329 - val_acc: 0.4980\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7044e-04 - categorical_crossentropy: 0.0052 - acc: 1.0000 - val_loss: 0.3570 - val_categorical_crossentropy: 1.9336 - val_acc: 0.4980\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.6917e-04 - categorical_crossentropy: 0.0052 - acc: 1.0000 - val_loss: 0.3571 - val_categorical_crossentropy: 1.9343 - val_acc: 0.4980\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.6789e-04 - categorical_crossentropy: 0.0052 - acc: 1.0000 - val_loss: 0.3573 - val_categorical_crossentropy: 1.9350 - val_acc: 0.4980\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.6657e-04 - categorical_crossentropy: 0.0052 - acc: 1.0000 - val_loss: 0.3574 - val_categorical_crossentropy: 1.9357 - val_acc: 0.4980\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.6519e-04 - categorical_crossentropy: 0.0051 - acc: 1.0000 - val_loss: 0.3575 - val_categorical_crossentropy: 1.9364 - val_acc: 0.4980\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.6367e-04 - categorical_crossentropy: 0.0051 - acc: 1.0000 - val_loss: 0.3577 - val_categorical_crossentropy: 1.9372 - val_acc: 0.4980\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.6187e-04 - categorical_crossentropy: 0.0051 - acc: 1.0000 - val_loss: 0.3578 - val_categorical_crossentropy: 1.9381 - val_acc: 0.4980\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5974e-04 - categorical_crossentropy: 0.0050 - acc: 1.0000 - val_loss: 0.3580 - val_categorical_crossentropy: 1.9391 - val_acc: 0.5000\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.5774e-04 - categorical_crossentropy: 0.0050 - acc: 1.0000 - val_loss: 0.3582 - val_categorical_crossentropy: 1.9400 - val_acc: 0.5000\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.5625e-04 - categorical_crossentropy: 0.0050 - acc: 1.0000 - val_loss: 0.3583 - val_categorical_crossentropy: 1.9407 - val_acc: 0.5000\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5502e-04 - categorical_crossentropy: 0.0049 - acc: 1.0000 - val_loss: 0.3585 - val_categorical_crossentropy: 1.9414 - val_acc: 0.5000\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.5387e-04 - categorical_crossentropy: 0.0049 - acc: 1.0000 - val_loss: 0.3586 - val_categorical_crossentropy: 1.9420 - val_acc: 0.5000\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.5274e-04 - categorical_crossentropy: 0.0049 - acc: 1.0000 - val_loss: 0.3587 - val_categorical_crossentropy: 1.9426 - val_acc: 0.5000\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5163e-04 - categorical_crossentropy: 0.0049 - acc: 1.0000 - val_loss: 0.3588 - val_categorical_crossentropy: 1.9431 - val_acc: 0.5000\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.5052e-04 - categorical_crossentropy: 0.0048 - acc: 1.0000 - val_loss: 0.3589 - val_categorical_crossentropy: 1.9436 - val_acc: 0.5000\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4943e-04 - categorical_crossentropy: 0.0048 - acc: 1.0000 - val_loss: 0.3589 - val_categorical_crossentropy: 1.9440 - val_acc: 0.5000\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4835e-04 - categorical_crossentropy: 0.0048 - acc: 1.0000 - val_loss: 0.3590 - val_categorical_crossentropy: 1.9445 - val_acc: 0.5000\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.4728e-04 - categorical_crossentropy: 0.0048 - acc: 1.0000 - val_loss: 0.3591 - val_categorical_crossentropy: 1.9449 - val_acc: 0.5000\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.4621e-04 - categorical_crossentropy: 0.0048 - acc: 1.0000 - val_loss: 0.3592 - val_categorical_crossentropy: 1.9454 - val_acc: 0.5000\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4515e-04 - categorical_crossentropy: 0.0047 - acc: 1.0000 - val_loss: 0.3593 - val_categorical_crossentropy: 1.9461 - val_acc: 0.5000\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4410e-04 - categorical_crossentropy: 0.0047 - acc: 1.0000 - val_loss: 0.3595 - val_categorical_crossentropy: 1.9470 - val_acc: 0.5000\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4306e-04 - categorical_crossentropy: 0.0047 - acc: 1.0000 - val_loss: 0.3597 - val_categorical_crossentropy: 1.9483 - val_acc: 0.5000\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4202e-04 - categorical_crossentropy: 0.0047 - acc: 1.0000 - val_loss: 0.3600 - val_categorical_crossentropy: 1.9496 - val_acc: 0.5000\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.4099e-04 - categorical_crossentropy: 0.0047 - acc: 1.0000 - val_loss: 0.3601 - val_categorical_crossentropy: 1.9505 - val_acc: 0.5000\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.3997e-04 - categorical_crossentropy: 0.0046 - acc: 1.0000 - val_loss: 0.3602 - val_categorical_crossentropy: 1.9511 - val_acc: 0.5000\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.3895e-04 - categorical_crossentropy: 0.0046 - acc: 1.0000 - val_loss: 0.3603 - val_categorical_crossentropy: 1.9515 - val_acc: 0.5000\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.3794e-04 - categorical_crossentropy: 0.0046 - acc: 1.0000 - val_loss: 0.3604 - val_categorical_crossentropy: 1.9518 - val_acc: 0.5000\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.3689e-04 - categorical_crossentropy: 0.0046 - acc: 1.0000 - val_loss: 0.3604 - val_categorical_crossentropy: 1.9519 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# callback = [ keras.callbacks.EarlyStopping(monitor=\"val_acc\",\n",
    "#               min_delta=1e-4, patience=10)]\n",
    "\n",
    "num_nodes = whole_labels.shape[0]\n",
    "features_ = whole_features.todense()\n",
    "history = model_cora.fit(x = features_, \n",
    "                         y = y_train, \n",
    "                         sample_weight= train_mask,\n",
    "                         validation_data=(features_, y_val, val_mask),batch_size = num_nodes, epochs = 300, shuffle = False, workers=10, use_multiprocessing=True)"
   ]
  },
  {
   "source": [
    "## Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7394 - categorical_crossentropy: 2.0023 - acc: 0.3590\n"
     ]
    }
   ],
   "source": [
    "eval_results = model_cora.evaluate(features_, y_test, sample_weight=test_mask, batch_size=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}